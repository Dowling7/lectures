{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "015937c0",
   "metadata": {
    "id": "015937c0"
   },
   "source": [
    "<hr style=\"height: 1px;\">\n",
    "<i>This notebook was authored by the 8.S50x Course Team, Copyright 2022 MIT All Rights Reserved.</i>\n",
    "<hr style=\"height: 1px;\">\n",
    "<br>\n",
    "\n",
    "<h1>Lesson 20: Planetary Dynamics</h1>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "100dd6f6",
   "metadata": {
    "id": "100dd6f6"
   },
   "source": [
    "<a name='section_20_0'></a>\n",
    "<hr style=\"height: 1px;\">\n",
    "\n",
    "\n",
    "## <h2 style=\"border:1px; border-style:solid; padding: 0.25em; color: #FFFFFF; background-color: #90409C\">L20.0 Overview</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d626a1f3",
   "metadata": {
    "id": "d626a1f3"
   },
   "source": [
    "<h3>Navigation</h3>\n",
    "\n",
    "<table style=\"width:100%\">\n",
    "    <tr>\n",
    "        <td style=\"text-align: left; vertical-align: top; font-size: 10pt;\"><a href=\"#section_20_1\">L20.1 Simulating Planetary Motion</a></td>\n",
    "        <td style=\"text-align: left; vertical-align: top; font-size: 10pt;\"><a href=\"#exercises_20_1\">L20.1 Exercises</a></td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td style=\"text-align: left; vertical-align: top; font-size: 10pt;\"><a href=\"#section_20_2\">L20.2 Parallel Dynamics</a></td>\n",
    "        <td style=\"text-align: left; vertical-align: top; font-size: 10pt;\"><a href=\"#exercises_20_2\">L20.2 Exercises</a></td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td style=\"text-align: left; vertical-align: top; font-size: 10pt;\"><a href=\"#section_20_3\">L20.3 3-body Problem</a></td>\n",
    "        <td style=\"text-align: left; vertical-align: top; font-size: 10pt;\"><a href=\"#exercises_20_3\">L20.3 Exercises</a></td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td style=\"text-align: left; vertical-align: top; font-size: 10pt;\"><a href=\"#section_20_4\">L20.4 N-body Problem</a></td>\n",
    "        <td style=\"text-align: left; vertical-align: top; font-size: 10pt;\"><a href=\"#exercises_20_4\">L20.4 Exercises</a></td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td style=\"text-align: left; vertical-align: top; font-size: 10pt;\"><a href=\"#section_20_5\">L20.5 ML N-body Problem</a></td>\n",
    "        <td style=\"text-align: left; vertical-align: top; font-size: 10pt;\"><a href=\"#exercises_20_5\">L20.5 Exercises</a></td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td style=\"text-align: left; vertical-align: top; font-size: 10pt;\"><a href=\"#section_20_6\">L20.6 1D Hydrodynamical Solutions</a></td>\n",
    "        <td style=\"text-align: left; vertical-align: top; font-size: 10pt;\"><a href=\"#exercises_20_6\">L20.6 Exercises</a></td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td style=\"text-align: left; vertical-align: top; font-size: 10pt;\"><a href=\"#section_20_7\">L20.7 N-D Hydrodynamical Solutions</a></td>\n",
    "        <td style=\"text-align: left; vertical-align: top; font-size: 10pt;\"><a href=\"#exercises_20_7\">L20.7 Exercises</a></td>\n",
    "    </tr>\n",
    "</table>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "355337cc",
   "metadata": {
    "id": "355337cc"
   },
   "source": [
    "<h3>Learning Objectives</h3>\n",
    "\n",
    "Like what we saw for the pendulum, there are a broad range of techniques that can be used to numerically solve differential equations. Most numerical physics courses are taught by people who do a lot of this simulation, and as such like to dwell on the immense amount of work that has happened in the past 50 years.\n",
    "\n",
    "A lot of this work is built on a huge amount of trial and error with the successes and failures having names after the people who did them. This makes it a bit hard to follow for someone like myself who doesn't know these people. However, much of this trial and error can be consolidated into some broad physics concepts that we can teach without trying and failing as many times.\n",
    "\n",
    "In this lecture we are going to build up the Hamiltonian Monte-Carlo Methods that are used for n-body  simulations. This part of this course wil just touch on the main elements. However, there is rich literature associated with this effort. We will dicuss this later.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91384457",
   "metadata": {
    "id": "91384457"
   },
   "source": [
    "<h3>Installing Tools</h3>\n",
    "\n",
    "Before we do anything, let's make sure we install the tools we need."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e68d33b9",
   "metadata": {
    "id": "e68d33b9"
   },
   "source": [
    "<h3>Importing Libraries</h3>\n",
    "\n",
    "Before beginning, run the cell below to import the relevant libraries for this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce79c4a1",
   "metadata": {
    "id": "ce79c4a1"
   },
   "outputs": [],
   "source": [
    "import imageio\n",
    "from PIL import Image\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from scipy.integrate import odeint\n",
    "from scipy.optimize import minimize\n",
    "import csv\n",
    "from matplotlib.patches import Circle\n",
    "from scipy.integrate import solve_ivp\n",
    "from IPython.display import Image\n",
    "#nbody\n",
    "#https://courses.physics.ucsd.edu/2019/Winter/physics141/Lectures/Lecture14/renaud_thesis.pdf\n",
    "#https://www.tat.physik.uni-tuebingen.de/~schaefer/teach/fum2020/f/nbody_slides.pdf\n",
    "#https://github.com/bacook17/behalf/blob/master/behalf/octree.py\n",
    "#https://anaroxanapop.github.io/behalf/#Code"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35d404de",
   "metadata": {
    "id": "35d404de"
   },
   "source": [
    "<h3>Setting Default Figure Parameters</h3>\n",
    "\n",
    "The following code cell sets default values for figure parameters.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f977228f",
   "metadata": {
    "id": "f977228f"
   },
   "outputs": [],
   "source": [
    "#>>>RUN: L10.0-runcell02\n",
    "\n",
    "#set plot resolution\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "\n",
    "#set default figure parameters\n",
    "plt.rcParams['figure.figsize'] = (9,6)\n",
    "\n",
    "medium_size = 12\n",
    "large_size = 15\n",
    "\n",
    "plt.rc('font', size=medium_size)          # default text sizes\n",
    "plt.rc('xtick', labelsize=medium_size)    # xtick labels\n",
    "plt.rc('ytick', labelsize=medium_size)    # ytick labels\n",
    "plt.rc('legend', fontsize=medium_size)    # legend\n",
    "plt.rc('axes', titlesize=large_size)      # axes title\n",
    "plt.rc('axes', labelsize=large_size)      # x and y labels\n",
    "plt.rc('figure', titlesize=large_size)    # figure title"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b22788c4",
   "metadata": {},
   "source": [
    "<a name='section_15_9'></a>\n",
    "<hr style=\"height: 1px;\">\n",
    "\n",
    "## <h2 style=\"border:1px; border-style:solid; padding: 0.25em; color: #FFFFFF; background-color: #90409C\">L15.9 Machine Learning the pendulum </h2>  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "689b9cad",
   "metadata": {},
   "source": [
    "Now that we have opened Pandora's box on deep learning, we can't go a lecture without discussing deep learning applications to everything. Deep learning for differential equations also has a very \"Physicsy\" moniker and is often called \"Physics Informed Machine Learninng\" (PIML) or sometimes \"Physics Informed Neural Networks\" (PINN). Ironically, the people who really pushed this are not physicists. \n",
    "\n",
    "The idea to do Physics Informed Machine Learning stems from the ability of neural networks to be function approximators. The simplest form is to do the same function style \"fitting\" that we did for the deep learning regression. However, what we can do is modify our loss with the knowledge of the differential equation. \n",
    "\n",
    "To seed the idea, let's consider modifying the loss with an additional term given by our differential equation. For a damped harmonic oscillator we can write: \n",
    "\n",
    "$$\n",
    "F = -kx + \\mu\\dot{x} \\\\\n",
    "m \\ddot{x} = -kx - \\mu\\dot{x} \\\\\n",
    "m \\ddot{x} + mu\\dot{x} +  kx  = 0 \n",
    "$$\n",
    "Which means that to approximate the differential equation, we can write a loss term as\n",
    "\n",
    "$$\n",
    "\\mathcal{L_{\\rm constrained}} = \\left( m \\ddot{x} + \\mu\\dot{x} +  kx \\right)^2\n",
    "$$\n",
    "Which is just the unsigned residual of the differential equation. Now noting that we want to train for a neural network function $f(x|\\theta)$, we can write: \n",
    "$$\n",
    "\\dot{x} = \\frac{d}{dt}f(x|\\theta) \\\\\n",
    "\\ddot{x} = \\frac{d^{2}}{dt^{2}}f(x|\\theta) \n",
    "$$\n",
    "which we can presumably compute from the neural network. \n",
    "\n",
    "If we want to fit some data with this constraint embedded in it, we can then just write this as a combination of mean squared error with the constrained loss. \n",
    "\n",
    "$$\n",
    "\\mathcal{L} = \\sum_{i} (x_{i}-f\\left(t|\\theta\\right))^{2} + \\mathcal{L_{\\rm constrained}}\n",
    "$$\n",
    "\n",
    "Now the tricky part is doing the computation of the additional \"constrained\" loss term. This will require that we can take derivatives of the neural network. Before, we get to that point, lets do a little setup. \n",
    "\n",
    "To start with we, will do this experimentw ith some toy data generated off the damped harmonic oscillator form. The solution for this function is \n",
    "\n",
    "$$\n",
    "x(t) = A e^{-\\kappa t} \\cos(\\omega t + \\phi) \\\\\n",
    "\\kappa = \\frac{\\mu}{2m} \\\\\n",
    "\\omega = \\sqrt{\\omega_{0}^2+\\kappa^2} \\\\\n",
    "\\omega_{0} = \\sqrt{\\frac{k}{m}}\n",
    "$$\n",
    "with $\\phi$ and $A$ as the phase an amplitude of our differential equation, that are set by the initial conditions ($A$ is intial position, $\\phi$ is related to the initial velocity).  For the case where $x(0)=1$ and $\\dot{x}=0$ we can write \n",
    "$$\n",
    "\\phi = \\tan^{-1}\\left(-\\frac{\\kappa}{\\omega}\\right) \\\\\n",
    "A    = \\frac{1}{2\\cos(\\phi)}\n",
    "$$\n",
    "\n",
    "Let's go ahead and code that up, also, lets make a neural network. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5438751e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def oscillator(d, w0, x):\n",
    "    w = np.sqrt(w0**2-d**2)\n",
    "    phi = np.arctan(-d/w)\n",
    "    A = 1/(2*np.cos(phi))\n",
    "    cos = torch.cos(phi+w*x)\n",
    "    sin = torch.sin(phi+w*x)\n",
    "    exp = torch.exp(-d*x)\n",
    "    y  = exp*2*A*cos\n",
    "    return y\n",
    "\n",
    "class MLP(nn.Module):    \n",
    "    def __init__(self, N_INPUT, N_OUTPUT, N_HIDDEN):\n",
    "        super().__init__()\n",
    "        activation = nn.Tanh\n",
    "        self.input = nn.Sequential(\n",
    "                        nn.Linear(N_INPUT, N_HIDDEN),\n",
    "                        activation()\n",
    "                      )\n",
    "        self.hidden = nn.Sequential(\n",
    "                    nn.Linear(N_HIDDEN, N_HIDDEN),\n",
    "                    activation(),\n",
    "                    nn.Linear(N_HIDDEN, N_HIDDEN),\n",
    "                    activation(),\n",
    "                    nn.Linear(N_HIDDEN, N_HIDDEN),\n",
    "                    activation(),        \n",
    "                    )\n",
    "\n",
    "        self.output = nn.Linear(N_HIDDEN, N_OUTPUT)\n",
    "        #self.fcs = nn.Sequential(*[nn.Linear(N_INPUT, N_HIDDEN),activation()])\n",
    "        #self.fch = nn.Sequential(*[nn.Sequential(*[nn.Linear(N_HIDDEN, N_HIDDEN),activation()]) for _ in range(N_LAYERS-1)])\n",
    "        #self.fce = nn.Linear(N_HIDDEN, N_OUTPUT)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.input(x)\n",
    "        x = self.hidden(x)\n",
    "        x = self.output(x)\n",
    "        return x\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f17579d",
   "metadata": {},
   "source": [
    "Now, what we can do is make some toy data from our damped harmonic oscillator. To do this, we will generate this right in pytorch, which will make it easier to train and evulate going forward. In this instance we ill generate a precise dataset, then we will take just one event every 20th and run our evaluation on it. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6956fead",
   "metadata": {},
   "outputs": [],
   "source": [
    "d, w0 = 2, 20\n",
    "\n",
    "# get the analytical solution over the full domain\n",
    "x = torch.linspace(0,1,500).view(-1,1)\n",
    "y = oscillator(d, w0, x).view(-1,1)\n",
    "\n",
    "# slice out a small number of points from the LHS of the domain\n",
    "x_data = x[0:200:20] # take just one event every 20th from 0 to 200\n",
    "y_data = y[0:200:20]\n",
    "print(x_data.shape, y_data.shape)\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(x, y, label=\"Exact solution\")\n",
    "plt.scatter(x_data, y_data, color=\"tab:orange\", label=\"Training data\")\n",
    "plt.xlabel('time')\n",
    "plt.ylabel('Amplitude')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da128622",
   "metadata": {},
   "source": [
    "Now before we compute the full differential equation, lets go ahead and run a quick training to see how the performance looks if we just try to fit the first few points of this distribution. This is just like what we had with the deep learning regression lecture a few weeks ago. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fe1dc88",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_result(x,y,x_data,y_data,yh,fig,ax,images=[],xp=None):\n",
    "    plt.cla()\n",
    "    plt.plot(x,y, color=\"grey\", linewidth=2, alpha=0.8, label=\"Exact solution\")\n",
    "    plt.plot(x,yh, color=\"tab:blue\", linewidth=4, alpha=0.8, label=\"Neural network prediction\")\n",
    "    plt.scatter(x_data, y_data[:,0], s=60, color=\"tab:orange\", alpha=0.4, label='Training data')\n",
    "    if xp is not None:\n",
    "        plt.scatter(xp, -0*torch.ones_like(xp), s=60, color=\"tab:green\", alpha=0.4, \n",
    "                    label='Physics loss training locations')\n",
    "    l = plt.legend(loc=(0.865,0.60), frameon=False, fontsize=\"large\")\n",
    "    plt.setp(l.get_texts(), color=\"k\")\n",
    "    plt.xlim(-0.05, 1.05)\n",
    "    plt.ylim(-1.1, 1.1)\n",
    "    plt.text(0.865,0.7,\"Training step: %i\"%(i+1),fontsize=\"xx-large\",color=\"k\")\n",
    "    plt.axis(\"off\")\n",
    "    fig.canvas.draw() \n",
    "    image = np.frombuffer(fig.canvas.tostring_rgb(), dtype='uint8')\n",
    "    image  = image.reshape(fig.canvas.get_width_height()[::-1] + (3,))\n",
    "    images.append(image)\n",
    "\n",
    "    \n",
    "# train standard neural network to fit training data\n",
    "torch.manual_seed(123)\n",
    "model = MLP(1,1,32)\n",
    "optimizer = torch.optim.Adam(model.parameters(),lr=1e-3)\n",
    "images = []\n",
    "fig, ax = plt.subplots(figsize=(10,5))\n",
    "y_data=torch.hstack((y_data,torch.ones(10,1)))\n",
    "for i in range(1000):\n",
    "    optimizer.zero_grad()\n",
    "    yh = model(x_data)\n",
    "    loss = torch.mean((yh[:,0:1]-y_data[:,0:1])**2)# use mean squared error\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    # plot the result as training progresses\n",
    "    if (i+1) % 1000 == 0: \n",
    "        print(loss.item())\n",
    "        yh = model(x).detach()\n",
    "        plot_result(x,y,x_data,y_data,yh,fig,ax,images)\n",
    "\n",
    "from IPython.display import Image\n",
    "a=imageio.mimsave('./training.gif', images, fps=10)\n",
    "Image(open('training.gif','rb').read())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27c8c150",
   "metadata": {},
   "source": [
    "Now the fit is suprisingly good. In fact from the few points that we have fit so well, we can potentially start to glimmer how we can find the period, decay constant and other parameters of the fit. However this is actually not an obvious question, when you think about it. \n",
    "\n",
    "*Can you figure out how we extract period, force, other fundamental parameters from the NN?* \n",
    "\n",
    "The answer to this might not be so satisfying. The only way we really know how to do this is by relying on our original knowledge of the differential equation. \n",
    "\n",
    "Recall from the pendulum that we have \n",
    "\n",
    "$$\n",
    "\\ddot{x(t)} = -\\frac{k}{m} x(t) - \\mu\\dot{x}\n",
    "$$\n",
    "\n",
    "From the above equation, we have computed $x(t)$, this is just our neural network, which I remind you **is differentiable**. Likewise, we can compute this quickly with pytorch. Let's go ahead and do that and take a look at what we see. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cabc6cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#First lets apply the model\n",
    "x_physics = torch.linspace(0,1,30).view(-1,1).requires_grad_(True)# sample locations over the problem domain\n",
    "yhp = model(x_physics)\n",
    "dx  = torch.autograd.grad(yhp, x_physics, torch.ones_like(yhp), create_graph=True)[0]# computes dy/dx\n",
    "dx2 = torch.autograd.grad(dx,  x_physics, torch.ones_like(dx),  create_graph=True)[0]# computes d^2y/dx^2\n",
    "dx*=0.1\n",
    "dx2*=0.01\n",
    "plt.plot(x,y, color=\"grey\", linewidth=2, alpha=0.8, label=\"Exact solution\")\n",
    "plt.plot(x,yh, color=\"tab:blue\", linewidth=4, alpha=0.8, label=\"Neural network prediction\")\n",
    "plt.scatter(x_physics.detach(), yhp.detach().numpy(), s=60, color=\"tab:orange\", alpha=0.4, label='Training data')\n",
    "plt.scatter(x_physics.detach(), dx.detach(), s=60, color=\"tab:green\", alpha=0.4, label='0.1(dx/dt)')\n",
    "plt.scatter(x_physics.detach(), dx2.detach(), s=60, color=\"tab:cyan\", alpha=0.4, label='0.01(d$^{2}$x/dt$^{2}$)')\n",
    "plt.scatter(x_physics.detach(), 0.1*dx2.detach()/yhp.detach(), s=60, color=\"blue\", alpha=0.4, label='0.01(d$^{2}$x/dt$^{2}$)/x(t)')\n",
    "plt.ylim(-3,3)\n",
    "plt.legend()\n",
    "plt.xlabel(\"time(s)\")\n",
    "plt.ylabel(\"x(t)\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed6835a1",
   "metadata": {},
   "source": [
    "Now what this means is we can embed this function into our loss. What we will now do is what we discussed above. We will define two losses: \n",
    "\n",
    " * Mean Squared Error Loss\n",
    " * Differential Equation residual\n",
    " \n",
    "Where we we will now define our differential equation loss as we did above\n",
    "\n",
    "$$\n",
    "\\mathcal{L} = \\sum_{i} (x_{i}-f\\left(t|\\theta\\right))^{2} + \\mathcal{L_{\\rm constrained}}\\\\\n",
    "\\mathcal{L_{\\rm constrained}} = \\left( m \\ddot{x} + \\mu\\dot{x} +  kx \\right)^2\n",
    "$$\n",
    "\n",
    "To make our lives simple, we will first do this with the knowledge of $\\mu$ and $\\omega_{0}$. However, we will eventually deviate away from this. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8bb7d43",
   "metadata": {},
   "outputs": [],
   "source": [
    "#x_physics = torch.linspace(0,1,30).view(-1,1).requires_grad_(True)# sample locations over the problem domain\n",
    "mu, k = 2*d, w0**2\n",
    "model = MLP(1,1,32)\n",
    "optimizer = torch.optim.Adam(model.parameters(),lr=1e-4)\n",
    "\n",
    "torch.manual_seed(123)\n",
    "images = []\n",
    "fig, ax = plt.subplots(figsize=(10,5))\n",
    "for i in range(20000):\n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    # compute the \"data loss\"\n",
    "    yh = model(x_data)\n",
    "    loss1 = torch.mean((yh[:,0:1]-y_data[:,0:1])**2)# use mean squared error\n",
    "\n",
    "    # compute the \"physics loss\"\n",
    "    yhp = model(x_physics)\n",
    "    dx  = torch.autograd.grad(yhp, x_physics, torch.ones_like(yhp), create_graph=True)[0]# computes dy/dx\n",
    "    dx2 = torch.autograd.grad(dx,  x_physics, torch.ones_like(dx),  create_graph=True)[0]# computes d^2y/dx^2\n",
    "    physics = dx2 +  mu*dx +  k*yhp# computes the residual of the 1D harmonic oscillator differential equation\n",
    "    loss2 = (1e-4)*torch.mean(physics**2)\n",
    "    \n",
    "    # backpropagate joint loss\n",
    "    loss = loss1 + loss2# add two loss terms together\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    \n",
    "    # plot the result as training progresses\n",
    "    if (i+1) % 1000 == 0: \n",
    "        \n",
    "        yh = model(x).detach()\n",
    "        xp = x_physics.detach()\n",
    "\n",
    "        print(loss.item())\n",
    "        yh = model(x).detach()\n",
    "        plot_result(x,y,x_data,y_data,yh,fig,ax,images)\n",
    "\n",
    "from IPython.display import Image\n",
    "a=imageio.mimsave('./training.gif', images, fps=10)\n",
    "Image(open('training.gif','rb').read())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb3be776",
   "metadata": {},
   "source": [
    "I have to say I am starting to get amazed. Our neural network is prediciting the whole shape of the the decaying exponent just with the knowledge of a few datapoints, and the full differential equation. Its really extrapoloating far away from what we have done. \n",
    "\n",
    "However, we have kind of cheated since we embedded in the loss a knowledge of the physics parameters that we are using. Let's try to learn these parameters too, so that we really learn everything. \n",
    "\n",
    "The way we are going to do this is we are going to make two neural networks and run them simultaneously. We will train one for our prediction, and we will train one for our parameters. I know this is kind of crazy, but let's see how it goes?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bb32348",
   "metadata": {},
   "outputs": [],
   "source": [
    "#x_physics = torch.linspace(0,1,30).view(-1,1).requires_grad_(True)# sample locations over the problem domain\n",
    "mu, k = 2*d, w0**2\n",
    "model1 = MLP(1,1,32)\n",
    "model2 = MLP(1,2,1)\n",
    "#model2.Train = False\n",
    "\n",
    "optimizer1 = torch.optim.Adam(model1.parameters(),lr=1e-4)\n",
    "optimizer2 = torch.optim.Adam(model2.parameters(),lr=1e-2)\n",
    "\n",
    "torch.manual_seed(123)\n",
    "images = []\n",
    "fig, ax = plt.subplots(figsize=(10,5))\n",
    "for i in range(50000):\n",
    "    optimizer1.zero_grad()\n",
    "    optimizer2.zero_grad()\n",
    "    \n",
    "    # compute the \"data loss\"\n",
    "    yh = model1(x_data)\n",
    "    loss1 = torch.mean((yh[:,0:1]-y_data[:,0:1])**2)# use mean squared error\n",
    "\n",
    "    # compute the \"physics loss\"\n",
    "    yhp   = model1(x_physics)\n",
    "    decay = model2(x_physics)\n",
    "    dx  = torch.autograd.grad(yhp, x_physics, torch.ones_like(yhp), create_graph=True)[0]# computes dy/dx\n",
    "    dx2 = torch.autograd.grad(dx,  x_physics, torch.ones_like(dx),  create_graph=True)[0]# computes d^2y/dx^2\n",
    "    physics = dx2 +  torch.mean(decay[:,0:1])*dx +  torch.mean(decay[:,1:2])*yhp# computes the residual of the 1D harmonic oscillator differential equation\n",
    "    loss2 = (1e-4)*torch.mean(physics**2)\n",
    "    \n",
    "    # backpropagate joint loss\n",
    "    loss = loss1 + loss2# add two loss terms together\n",
    "    loss.backward()\n",
    "    optimizer1.step()\n",
    "    optimizer2.step()\n",
    "    \n",
    "    \n",
    "    # plot the result as training progresses\n",
    "    if (i+1) % 1000 == 0: \n",
    "        \n",
    "        yh = model1(x).detach()\n",
    "        xp = x_physics.detach()\n",
    "\n",
    "        print(loss.item())\n",
    "        yh = model1(x).detach()\n",
    "        plot_result(x,y,x_data,y_data,yh,fig,ax,images)\n",
    "\n",
    "from IPython.display import Image\n",
    "a=imageio.mimsave('./training.gif', images, fps=10)\n",
    "Image(open('training.gif','rb').read())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fe27053",
   "metadata": {},
   "source": [
    "Ok, now we need to see if the values make sense. Let's look at the output of our decay neural network and see what parameters it has predicted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46261ae2",
   "metadata": {},
   "outputs": [],
   "source": [
    "decays=model2(x_physics)\n",
    "print(\"NN Mu:\",decays[0][0].detach().numpy(),\"Actual:\",mu,\"NN k: \",decays[0][1].detach().numpy(),\"Actual:\",k)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f28813a",
   "metadata": {},
   "source": [
    "So we have pretty good numbers. For our decay constant ($\\mu$) we are a bit high. However, for our frequency (spring constant $k$) we are spot on, and we can predict the future. I know this seems kind of dumb, but I want to stress that we are giving the neural network 10 points and a constraint on the differential equation, and we are telling it to make a full prediction for the future. I don't know about you, but I am impressed. Just imagine trying to code up a much more complicated problems, its not that hard. \n",
    "\n",
    "One thing to note is that the neural network is pretty slow. It takes time to get this to converge. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56cc1139",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "90f4d84c",
   "metadata": {
    "id": "90f4d84c"
   },
   "source": [
    "<a name='section_20_1'></a>\n",
    "<hr style=\"height: 1px;\">\n",
    "\n",
    "## <h2 style=\"border:1px; border-style:solid; padding: 0.25em; color: #FFFFFF; background-color: #90409C\">L20.1 Simulating Planetary Motion</h2>  \n",
    "\n",
    "| [Top](#section_20_0) | [Previous Section](#section_20_0) | [Exercises](#exercises_20_1) | [Next Section](#section_20_2) |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4f03e0f",
   "metadata": {
    "id": "f4f03e0f"
   },
   "source": [
    "<h3>Overview</h3>\n",
    "\n",
    "This lecture will cover n-body simulations. The goal with n-body simulations is to be able to model stellar motion over many time periods. In practice, stellar motion boils down to just applications of Newton's laws, but on a variety of time and distance scales.\n",
    "\n",
    "The force for these two bodies is given by gravity, and we can write it as.\n",
    "\n",
    "$$\n",
    "\\vec{F} = \\frac{G m_{1}m_{2}}{|\\vec{q_{1}}-\\vec{q_{2}}|^{3}} \\left(\\vec{q_{1}}-\\vec{q_{2}}\\right)\n",
    "$$\n",
    "\n",
    "where $G$ is the gravitation constant $m_{1,2}$ are the black hole masses, and  $\\vec{q_{1}}$ and $\\vec{q_{2}}$ are coordinates in space that describe the positions of the black holes. To describe the motion, we will take the Hamiltonian formalism. The reason is that the momenta $p_{1,2}$ and postitions $q_{1,2}$ follow Liouville's theorem, or in otherwords, we can write for a closed system without any energy in and out\n",
    "\n",
    "$$\n",
    "\\frac{\\partial\\mathcal{H}}{\\partial t} + \\sum^{n}_{i=1} \\left(\\frac{\\partial \\mathcal{H}}{\\partial q_{i}}\\dot{q_{i}}+\\frac{\\partial\n",
    "\\mathcal{H}}{\\partial p_{i}}\\dot{p_{i}}\\right)=0 \\\\\n",
    "\\sum^{n}_{i=1}  \\left( \\frac{\\partial \\mathcal{H}} { \\partial q_{i} } \\dot{q_{i}}+\\frac{\\partial \\mathcal{H}}{\\partial p_{i}}\\dot{p_{i}}\\right) = 0\n",
    "$$\n",
    "\n",
    "where $\\rho$ is the density in momentum, position space is constant. Note that we can just get this by taking the time derivative (not just the partial) of the density $\\rho(p,q)$ and propagating the full derivative.  \n",
    "\n",
    "Let's consider a standard Hamiltonian for energy, given by\n",
    "$$\n",
    "H = \\frac{1}{2}\\vec{p}^2 + \\Phi(\\vec{q})\n",
    "$$\n",
    "for a potential $\\Phi$. Following the Hamiltonian formalism for motion, we can write Hamiltons equation as\n",
    "\n",
    "$$\n",
    "\\frac{\\partial H }{\\partial p_{i}} =  \\frac{d q_{i}}{dt} = \\vec{p} \\\\\n",
    "\\frac{\\partial H }{\\partial q_{i}} = -\\frac{d p_{i}}{dt} = -\\nabla \\Phi(\\vec{q_{i}}) \\\\\n",
    "$$\n",
    "The simplest solutions involve straight up integration, we can write these as\n",
    "\n",
    "$$\n",
    "q_{\\rm new} = \\vec{q} + \\Delta t \\vec{p} \\\\\n",
    "p_{\\rm new} = \\vec{p} - \\Delta t \\nabla \\Phi(\\vec{q_{i}}) \\\\\n",
    "$$\n",
    "\n",
    "Now from last class, we looked at the leap-frog Verlet stepping, which if you recall ensured that the determinant of the updates are 1 and that the stepping was volume preserving."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e54615c",
   "metadata": {
    "id": "2e54615c"
   },
   "source": [
    "<h3>Example of Sympletic approach</h3>\n",
    "\n",
    "As a reminder from last time, if we consider a Hamiltonian given by the harmonic oscillator our updates become\n",
    "$$\n",
    "H = \\frac{1}{2}\\vec{p}^2+\\frac{1}{2}\\vec{q}^2 \\\\\n",
    "q_{\\rm new} = \\vec{q} - \\Delta t \\vec{p} \\\\\n",
    "p_{\\rm new} = \\vec{p} + \\Delta t \\vec{q} \\\\\n",
    "H_{\\rm new} = \\frac{1}{2}\\vec{p_{\\rm new} }^2+\\frac{1}{2}\\vec{q_{\\rm new} }^2 \\\\\n",
    "H_{\\rm new} = \\frac{1}{2}(\\vec{p} + \\Delta t \\vec{q})^2+\\frac{1}{2}(q_{\\rm new} = \\vec{p} - \\Delta t \\vec{p})^2 \\\\\n",
    "H_{\\rm new} = \\frac{1}{2}\\vec{p}^2+\\frac{1}{2}\\vec{q}^2 + \\Delta t \\left(\\vec{p}^2+\\frac{1}{2}\\vec{q}^2\\right)\n",
    "$$\n",
    "\n",
    "Which for $\\Delta t > 0$ clearly does not conserve energy.  Effectively every time we update $\\Delta t$\n",
    "\n",
    "Now if we look at our update and in the context of the Hamiltonian, we can make this \"Symplectic\" by making sure that our system conserves energy. In this scenario, we can do this in an elegant way by noting that for a 1 dimensional system all paths lie on a circle in phase space (ie $2H=C=p^2+x^2$ is the equation of circle) This means that all updates of momentum and position can be written as rotations\n",
    "\n",
    "$$\n",
    "\\begin{pmatrix}\n",
    "x \\\\\n",
    "p\n",
    "\\end{pmatrix}\n",
    "=\n",
    "\\begin{pmatrix}\n",
    "\\cos \\theta & \\sin \\theta \\\\\n",
    "-\\sin \\theta & \\cos \\theta\n",
    "\\end{pmatrix}\n",
    "\\begin{pmatrix}\n",
    "x \\\\\n",
    "p\n",
    "\\end{pmatrix}\n",
    "$$\n",
    "And our updates above can be written\n",
    "$$\n",
    "\\begin{pmatrix}\n",
    "x \\\\\n",
    "p\n",
    "\\end{pmatrix}\n",
    "=\n",
    "\\begin{pmatrix}\n",
    "1 & \\Delta t \\\\\n",
    "-\\Delta t & 1\n",
    "\\end{pmatrix}\n",
    "\\begin{pmatrix}\n",
    "x \\\\\n",
    "p\n",
    "\\end{pmatrix}\n",
    "$$\n",
    "Which has a determinant $1+\\Delta t^2$ and is therefore not a rotation, (which have determinant 1) and the causes the phase space to increase. we can fix this by modifying our setup to correspond to a determinant of 1\n",
    "\n",
    "$$\n",
    "\\begin{pmatrix}\n",
    "x \\\\\n",
    "p\n",
    "\\end{pmatrix}\n",
    "=\n",
    "\\begin{pmatrix}\n",
    "1 & \\Delta t \\\\\n",
    "-\\Delta t & 1 -\\Delta t^2\n",
    "\\end{pmatrix}\n",
    "\\begin{pmatrix}\n",
    "x \\\\\n",
    "p\n",
    "\\end{pmatrix}\n",
    "$$\n",
    "However, you might notice already, this is looks weird, its not really a rotation or a taylor expansion of a rotation. In fact, we can do better, but lets just go with this for a sec. If we write out the full Hamiltonian of this setup, we have\n",
    "$$\n",
    "q_{\\rm new} = \\vec{p} - \\Delta t \\vec{p} \\\\\n",
    "p_{\\rm new} = (1-\\Delta t^2) \\vec{p} + \\Delta t \\vec{q} \\\\\n",
    "H_{\\rm new} = \\frac{1}{2}\\vec{p_{\\rm new} }^2+\\frac{1}{2}\\vec{q_{\\rm new} }^2 \\\\\n",
    "H_{\\rm new} = \\frac{1}{2}\\vec{p}^2+\\frac{1}{2}\\vec{q}^2 + \\Delta t^2 \\left(q^2-p^2\\right) + 2\\Delta t^3 qp + \\Delta t^4 p^2\n",
    "$$\n",
    "which doesn't conserve the Hamiltonian, but because the determinant in phase space is 1, it is energy conserving, its just not for the Hamiltonian we care about. It turns out that its for\n",
    "$$\n",
    "H_{\\rm modified} = \\frac{1}{2}\\vec{p}^2+\\frac{1}{2}\\vec{q}^2  + \\frac{\\Delta t}{2} p q\n",
    "$$\n",
    "This is crazy. What this means is that the timestep determines the conserved energy. This also means that we have to consider these elements when constructing our simulation if we want to make our simulation \"simplectic\" or energy preserving. There is no ideal solution to this. However, what this means is that we can make a \"modified Hamiltoniain\" denoted\n",
    "$$\n",
    "H_{\\rm modified} = H_{\\rm true} + H_{\\rm error}\n",
    "$$\n",
    "Importantly, if we change the time-step through a so-called \"adaptive time step\", we will break our conservation law in this scenario.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9e9aa5c",
   "metadata": {
    "id": "b9e9aa5c"
   },
   "source": [
    "<h3>Back to gravity</h3>\n",
    "\n",
    "Let's write this in the context of Gravity\n",
    "\n",
    "$$\n",
    "H = \\frac{\\vec{p_{1}}^2}{2m_{1}} + \\frac{\\vec{p_{2}}^2}{2m_{2}} - \\frac{Gm_{1}m_{2}}{|\\vec{q_{1}}-\\vec{q_{2}}|}\n",
    "$$\n",
    "\n",
    "This is a formula that we all know well. Despite it being two particles, we can write this in the center of mass frame as the motion of a single particle.  This gives us the constraint that\n",
    "\n",
    "$$\n",
    "m_{1}\\vec{q}_{1} + m_{2}\\vec{q}_{2} = 0\n",
    "$$\n",
    "\n",
    "Let's go ahead and comput the force, and step it through, one thing we are going to do is modify our potential term slightly by\n",
    "\n",
    "$$\n",
    "H = \\frac{\\vec{p_{1}}^2}{2m_{1}} + \\frac{\\vec{p_{2}}^2}{2m_{2}} - \\frac{Gm_{1}m_{2}}{|\\vec{q_{1}}-\\vec{q_{2}}+\\epsilon|}\n",
    "$$\n",
    "\n",
    "This term $\\epsilon$ is known as the softening term and it exists to avoid infinities. Let's go ahead and write everything out. The simplest verision of stepping we can do is\n",
    "\n",
    "$$\n",
    "\\vec{q_{1}} = \\vec{q_{1}}+\\vec{v_{1}}\\Delta t \\\\\n",
    "\\vec{v_{1}} = \\vec{v_{1}}+\\Delta t \\frac{G m_{2}}{|\\vec{q_{1}}-\\vec{q_{2}}+\\epsilon|^{3}}\\left(\\vec{q_{1}}-\\vec{q_{2}}\\right) \\\\\n",
    "\\vec{r_{2}} = \\vec{q_{2}}+\\vec{v_{2}}\\Delta t \\\\\n",
    "\\vec{v_{2}} = \\vec{v_{2}}+\\Delta t \\frac{G m_{1}}{|\\vec{q_{2}}-\\vec{q_{1}}+\\epsilon|^{3}}\\left(\\vec{q_{2}}-\\vec{q_{1}}\\right) \\\\\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcb3e789",
   "metadata": {
    "id": "bcb3e789"
   },
   "source": [
    "To step this, we are going to construct this with a python class. The strategy here is to be able to run this for an arbitrary amount of stars in the future siulations.\n",
    "\n",
    "As a result, we are going to simulate this with the leapfrog setup.\n",
    "\n",
    "With all simulations, we want to start with a basic check for what is going on. We can do this by just simulating circular motion.\n",
    "\n",
    "$$\n",
    "F_{c} = \\frac{mv^2}{r} = \\frac{G Mm}{(2r)^2}\\\\\n",
    "v     = \\sqrt{\\frac{GM}{4r}}\n",
    "$$\n",
    "\n",
    "Lets go ahead and do this. Note, that from the computation side, we will do this in a more object oriented way, by making a Star class. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bde46ee",
   "metadata": {
    "id": "1bde46ee",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#Units\n",
    "Gc=39.478 #AU^3/yr^2/Msun\n",
    "re=1.0#AU\n",
    "ve=2*np.pi*re#2pir/yr\n",
    "Gmod=Gc/re**2\n",
    "\n",
    "class star:\n",
    "    #Save the history\n",
    "    posh = np.array([])\n",
    "    velh = np.array([])\n",
    "    poth = np.array([])\n",
    "    kinh = np.array([])\n",
    "    soften =  1e-6\n",
    "\n",
    "    def __init__(self,imass,xinit,yinit,vxinit,vyinit):\n",
    "        self.mass = imass\n",
    "        self.rpos = np.array([xinit,yinit])\n",
    "        self.v    = np.array([vxinit,vyinit])\n",
    "        self.a    = np.array([0.,0.])\n",
    "        self.u    = 0\n",
    "\n",
    "    def firststep(self,dt):\n",
    "        self.rpos=self.rpos+0.5*dt*self.v\n",
    "\n",
    "    def firststepv(self,dt):\n",
    "        self.v=self.v   +0.5*dt*self.a\n",
    "        self.rpos=self.rpos+dt*self.v\n",
    "        self.a[0] = 0.\n",
    "        self.a[1] = 0.\n",
    "        self.u    = 0.\n",
    "\n",
    "    def step(self,dt):\n",
    "        #vnew = self.v   +dt*self.a\n",
    "        #self.rpos=self.rpos+dt*self.v\n",
    "        #self.v   =vnew\n",
    "        self.v    = self.v   +dt*self.a\n",
    "        self.rpos = self.rpos+dt*self.v\n",
    "        self.posh = np.append(self.posh,self.rpos)\n",
    "        self.velh = np.append(self.velh,self.v)\n",
    "        self.poth = np.append(self.poth,self.u)\n",
    "        self.kinh = np.append(self.kinh,0.5*self.mass*(np.dot(self.v,self.v)))\n",
    "        #reset\n",
    "        self.a[0] = 0.\n",
    "        self.a[1] = 0.\n",
    "        self.u    = 0.\n",
    "\n",
    "    def force(self,istar):#Force with respect to star\n",
    "        drv=istar.rpos-self.rpos\n",
    "        drs=np.dot(drv,drv)+self.soften\n",
    "        df=Gmod*drv*(drs**(-1.5))\n",
    "        self.a  += (istar.mass)*df\n",
    "        istar.update(df,self.mass)\n",
    "\n",
    "    def update(self,df,imass):\n",
    "        self.a += -imass*df\n",
    "\n",
    "    def update_u(self,iU):\n",
    "        self.u += iU\n",
    "\n",
    "    def potential(self,istar):\n",
    "        drv=istar.rpos-self.rpos\n",
    "        drs=(np.dot(drv,drv))**(-0.5)\n",
    "        ulocal = -1.*0.5*Gmod*drs*self.mass*istar.mass\n",
    "        self.u += ulocal\n",
    "        istar.update_u(ulocal)\n",
    "\n",
    "#now to get things going we are going to simulate a cricle\n",
    "def circle_v(iM,iR):\n",
    "    #F=mv^2/r = GMm/(2r)^2=>v=sqrt(GM/4r)\n",
    "    return np.sqrt(Gc*iM/(4*iR))\n",
    "\n",
    "def sim(dt=0.001,nsteps=10000):\n",
    "    radius=1#units of AU\n",
    "    mass=1#units of Solar Mass\n",
    "    vup=circle_v(mass,radius)\n",
    "    a1=star(mass, radius,0,0, vup)\n",
    "    a2=star(mass,-radius,0,0,-vup)\n",
    "    a1.firststepv(dt)\n",
    "    a2.firststepv(dt)\n",
    "    for t in range(nsteps):\n",
    "        a1.force(a2)\n",
    "        a1.potential(a2)\n",
    "        a1.step(dt)\n",
    "        a2.step(dt)\n",
    "    #plot the history of these guys\n",
    "    x1vals=np.reshape(a1.posh,(len(a1.posh)//2,2))\n",
    "    x2vals=np.reshape(a2.posh,(len(a2.posh)//2,2))\n",
    "    plt.plot(x1vals[:,0],x1vals[:,1])\n",
    "    plt.plot(x2vals[:,0],x2vals[:,1])\n",
    "    plt.show()\n",
    "\n",
    "    #Plot the energy of these guys\n",
    "    plt.plot(range(nsteps),a1.poth+a2.poth,label='potential')\n",
    "    plt.plot(range(nsteps),a1.kinh+a2.kinh,label='kinetic')\n",
    "    plt.plot(range(nsteps),a1.kinh+a2.kinh+a1.poth+a2.poth,label='Total')\n",
    "    plt.legend()\n",
    "    plt.xlabel('time step')\n",
    "    plt.ylabel('energy')\n",
    "    plt.show()\n",
    "\n",
    "#First a simple simulation\n",
    "sim(nsteps=10000)\n",
    "#Now a simulation with a coarse timestep\n",
    "#sim(dt=0.1,nsteps=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3a05d6c",
   "metadata": {
    "id": "a3a05d6c"
   },
   "source": [
    "It's worth noting that with the leap-frog integrator, there are still varations in the energy of the system.  We see this above with the coarse stepped version of the simulator. We can see this by zooming in on the energy regions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd9d5a52",
   "metadata": {
    "id": "cd9d5a52"
   },
   "outputs": [],
   "source": [
    "def norm(iVal):\n",
    "    return iVal/np.mean(iVal)\n",
    "\n",
    "def simNormE():\n",
    "    dt=0.001 #units of years\n",
    "    radius=1#units of AU\n",
    "    mass=1#units of Solar Mass\n",
    "    vup=circle_v(mass,radius)\n",
    "    a1=star(mass, radius,0,0, vup)\n",
    "    a2=star(mass,-radius,0,0,-vup)\n",
    "    nsteps=10000\n",
    "    a1.firststepv(dt)\n",
    "    a2.firststepv(dt)\n",
    "    for t in range(nsteps):\n",
    "        a1.force(a2)\n",
    "        a1.potential(a2)\n",
    "        a1.step(dt)\n",
    "        a2.step(dt)\n",
    "\n",
    "    plt.plot(range(nsteps),norm(a1.poth+a2.poth),label='potential')\n",
    "    plt.plot(range(nsteps),norm(a1.kinh+a2.kinh),label='kinetic')\n",
    "    plt.plot(range(nsteps),norm(a1.kinh+a2.kinh+a1.poth+a2.poth),label='Total',c='g')\n",
    "    plt.legend()\n",
    "    plt.xlabel('time step')\n",
    "    plt.ylabel('energy')\n",
    "    plt.show()\n",
    "\n",
    "simNormE()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc7ed823",
   "metadata": {
    "id": "dc7ed823"
   },
   "source": [
    "More importantly because the leap-frog step is simplectic(energy conserving) even though the stepping is not accurate, we have that a large number of iterations still preserves the overall energy of the system. This is really the most critical component of the leap-frog setup. As a result, it remains the current basis for how we do stellar simulations.  \n",
    "\n",
    "Now for good measure, lets animate our setup."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8abf0b92",
   "metadata": {
    "id": "8abf0b92"
   },
   "outputs": [],
   "source": [
    "from matplotlib.animation import FuncAnimation\n",
    "from IPython.display import HTML\n",
    "\n",
    "def simNoPlot(dt=0.001,nsteps=10000):\n",
    "    radius=1#units of AU\n",
    "    mass=1#units of Solar Mass\n",
    "    vup=circle_v(mass,radius)\n",
    "    a1=star(mass, radius,0,0, vup)\n",
    "    a2=star(mass,-radius,0,0,-vup)\n",
    "    a1.firststepv(dt)\n",
    "    a2.firststepv(dt)\n",
    "    for t in range(nsteps):\n",
    "        a1.force(a2)\n",
    "        a1.potential(a2)\n",
    "        a1.step(dt)\n",
    "        a2.step(dt)\n",
    "    x1vals=np.reshape(a1.posh,(len(a1.posh)//2,2))\n",
    "    x2vals=np.reshape(a2.posh,(len(a2.posh)//2,2))\n",
    "    return np.array([x1vals,x2vals])\n",
    "\n",
    "\n",
    "def makePlot(nbody,coords,ax,fig,images,ymin=-2,ymax=2,xmin=-2,xmax=2):\n",
    "    # plot and show learning process\n",
    "    plt.cla()\n",
    "    ax.set_xlabel('x(AU)', fontsize=24)\n",
    "    ax.set_ylabel('y(AU)', fontsize=24)\n",
    "    ax.set_ylim(ymin,ymax)\n",
    "    ax.set_xlim(xmin,xmax)\n",
    "    for body in range(nbody):\n",
    "        #ax.plot(coords[body][-1,0],coords[body][-1,1],'o', color = '#d2eeff', markerfacecolor = '#0077BE')\n",
    "        ax.plot(np.flip(coords[body][:,0]),np.flip(coords[body][:,1]), 'o-',color = '#d2eeff',markevery=10000, markerfacecolor = '#0077BE',lw=2)\n",
    "    fig.canvas.draw()       # draw the canvas, cache the renderer\n",
    "    image = np.frombuffer(fig.canvas.tostring_rgb(), dtype='uint8')\n",
    "    image  = image.reshape(fig.canvas.get_width_height()[::-1] + (3,))\n",
    "    images.append(image)\n",
    "\n",
    "\n",
    "def animate(coords,iN=2,stepsize=50):\n",
    "    images = []\n",
    "    fig, ax = plt.subplots(figsize=(12,7))\n",
    "    for step in range(len(coords[0])-110):\n",
    "        if step % stepsize == 0:\n",
    "            makePlot(iN,coords[:,step:step+100],ax,fig,images)\n",
    "    return images\n",
    "\n",
    "\n",
    "xvals=simNoPlot()\n",
    "images=animate(xvals)\n",
    "imageio.mimsave('orbit.gif', images, fps=10)\n",
    "Image(open('orbit.gif','rb').read())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31c06b4f",
   "metadata": {
    "id": "31c06b4f"
   },
   "source": [
    "<a name='exercises_20_1'></a>     \n",
    "\n",
    "| [Top](#section_20_0) | [Restart Section](#section_20_1) | [Next Section](#section_20_2) |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1135e54f",
   "metadata": {
    "id": "1135e54f"
   },
   "source": [
    "### <span style=\"border:3px; border-style:solid; padding: 0.15em; border-color: #90409C; color: #90409C;\">Ex-20.1.1 </span>\n",
    "\n",
    "Repeat the above setup with the Euler step, what is going on?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c19072a2",
   "metadata": {
    "id": "c19072a2",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#>>>SOLUTION: L19.1.1\n",
    "\n",
    "class eulerstar:\n",
    "    #Sve the history\n",
    "    posh = np.array([])\n",
    "    velh = np.array([])\n",
    "    poth = np.array([])\n",
    "    kinh = np.array([])\n",
    "    soften =  1e-6\n",
    "\n",
    "    def __init__(self,imass,xinit,yinit,vxinit,vyinit):\n",
    "        self.mass = imass\n",
    "        self.rpos = np.array([xinit,yinit])\n",
    "        self.v    = np.array([vxinit,vyinit])\n",
    "        self.a    = np.array([0.,0.])\n",
    "        self.u    = 0\n",
    "\n",
    "    def firststep(self,dt):\n",
    "        self.rpos=self.rpos+0.5*dt*self.v\n",
    "\n",
    "    def firststepv(self,dt):\n",
    "        self.v=self.v   +0.5*dt*self.a\n",
    "        self.rpos=self.rpos+dt*self.v\n",
    "        self.a[0] = 0.\n",
    "        self.a[1] = 0.\n",
    "        self.u    = 0.\n",
    "\n",
    "    def step(self,dt):\n",
    "        vold=self.v\n",
    "        self.v    = self.v   +dt*self.a\n",
    "        self.rpos = self.rpos+dt*vold\n",
    "        self.posh = np.append(self.posh,self.rpos)\n",
    "        self.velh = np.append(self.velh,self.v)\n",
    "        self.poth = np.append(self.poth,self.u)\n",
    "        self.kinh = np.append(self.kinh,0.5*self.mass*(np.dot(self.v,self.v)))\n",
    "        #reset\n",
    "        self.a[0] = 0.\n",
    "        self.a[1] = 0.\n",
    "        self.u    = 0.\n",
    "\n",
    "    def force(self,istar):\n",
    "        drv=istar.rpos-self.rpos\n",
    "        drs=np.dot(drv,drv)+self.soften\n",
    "        df=Gmod*drv*(drs**(-1.5))\n",
    "        #if self.a[0] == 0: #something is f'd up\n",
    "        #    self.a  = (istar.mass)*df\n",
    "        #else:\n",
    "        self.a  += (istar.mass)*df\n",
    "        istar.update(df,self.mass)\n",
    "\n",
    "    def update(self,df,imass):\n",
    "        self.a += -imass*df\n",
    "\n",
    "    def update_u(self,iU):\n",
    "        self.u += iU\n",
    "\n",
    "    def potential(self,istar):\n",
    "        drv=istar.rpos-self.rpos\n",
    "        drs=(np.dot(drv,drv))**(-0.5)\n",
    "        ulocal = -1.*0.5*Gmod*drs*self.mass*istar.mass\n",
    "        self.u += ulocal\n",
    "        istar.update_u(ulocal)\n",
    "\n",
    "#now to get things going we are going to simulate a cricle\n",
    "def circle_v(iM,iR):\n",
    "    #F=mv^2/r = GMm/(2r)^2=>v=sqrt(GM/4r)\n",
    "    return np.sqrt(Gc*iM/(4*iR))\n",
    "\n",
    "def eulersim(dt=0.001,nsteps=10000):\n",
    "    radius=1#units of AU\n",
    "    mass=1#units of Solar Mass\n",
    "    vup=circle_v(mass,radius)\n",
    "    a1=eulerstar(mass, radius,0,0, vup)\n",
    "    a2=eulerstar(mass,-radius,0,0,-vup)\n",
    "    for t in range(nsteps):\n",
    "        a1.force(a2)\n",
    "        a1.potential(a2)\n",
    "        a1.step(dt)\n",
    "        a2.step(dt)\n",
    "    x1vals=np.reshape(a1.posh,(len(a1.posh)//2,2))\n",
    "    x2vals=np.reshape(a2.posh,(len(a2.posh)//2,2))\n",
    "    plt.plot(x1vals[:,0],x1vals[:,1])\n",
    "    plt.plot(x2vals[:,0],x2vals[:,1])\n",
    "    plt.show()\n",
    "\n",
    "    plt.plot(range(nsteps),a1.poth+a2.poth,label='potential')\n",
    "    plt.plot(range(nsteps),a1.kinh+a2.kinh,label='kinetic')\n",
    "    plt.plot(range(nsteps),a1.kinh+a2.kinh+a1.poth+a2.poth,label='Total')\n",
    "    plt.legend()\n",
    "    plt.xlabel('time step')\n",
    "    plt.ylabel('energy')\n",
    "    plt.show()\n",
    "\n",
    "eulersim()\n",
    "eulersim(dt=0.25,nsteps=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76b2a4e5",
   "metadata": {
    "id": "76b2a4e5"
   },
   "source": [
    "<div style=\"border:1.5px; border-style:solid; padding: 0.5em; border-color: #90409C; color: #90409C;\">\n",
    "\n",
    "**SOLUTION:**\n",
    "\n",
    "<pre>\n",
    "\n",
    "</pre>\n",
    "        \n",
    "**EXPLANATION:**\n",
    "    \n",
    "This shouldn't come as a surprise to anybody as this point. The Euler step does not conserve energy and so our orbit will slowly fall apart. The more we step it out, the more things get worse.\n",
    "    \n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c14dae3b",
   "metadata": {
    "id": "c14dae3b"
   },
   "source": [
    "<a name='section_20_2'></a>\n",
    "<hr style=\"height: 1px;\">\n",
    "\n",
    "## <h2 style=\"border:1px; border-style:solid; padding: 0.25em; color: #FFFFFF; background-color: #90409C\">L20.2 Parallel Dynamics</h2>  \n",
    "\n",
    "| [Top](#section_20_0) | [Previous Section](#section_20_1) | [Exercises](#exercises_20_2) | [Next Section](#section_20_3) |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91d57cc1",
   "metadata": {
    "id": "91d57cc1"
   },
   "source": [
    "<h3>Overview</h3>\n",
    "\n",
    "Now, given this  start, we would like to have some fun to explore the nature of this simulation to create interesting dynamics. With 2-bodies things are kind of trivial. However, when we go to 3-bodies, we suddenly have a very rich and interesting system, that we can explore.\n",
    "\n",
    "However before, we go there, lets take some time to speed up our simulation so that we can really get the best out of our computations.\n",
    "\n",
    "The best way to speed up the computation is to :\n",
    "\n",
    " * Use the numpy libraries as much as possible\n",
    " * Parallelize the computation\n",
    "\n",
    "To make this fast, what we will do is store all the stars in an array, and do the computation of Newton's lawas in parallel. As a result, lets make a class called \"stars\".\n",
    "\n",
    "The way we will compute the force is we will take a vector of x-positions, a vector of y-positions and comput the diferrences. To be clear let us define\n",
    "\n",
    "$$\n",
    "\\vec{x} = x_{i}\\hat{i} \\\\\n",
    "\\vec{y} = y_{i}\\hat{i} \\\\\n",
    "$$\n",
    "\n",
    "or the i-th element of the vector is the x and y position.  As a result, the difference in radius is defined as\n",
    "\n",
    "$$\n",
    "dx_{ij} = x_{j} - x_{i} = \\vec{x}^{T}-\\vec{x}\\\\\n",
    "dr_{ij} = \\sqrt{dx_{ij}^2 + dy_{ij}^2}\n",
    "$$\n",
    "\n",
    "here we hae computed a matrix $i$-$j$. We can then contract down this matrix by multiplying it by the respective coordinates. We can write this as:\n",
    "\n",
    "$$\n",
    "a^{i}_{x} = G m_{j} {dr_{ij}}^{-3} dx_{ij} \\\\\n",
    "$$\n",
    "To compress along an axis, we have to use the @ symboly\n",
    "\n",
    "Let's quickly play with some arrays so that we know whats going on.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce10f591",
   "metadata": {
    "id": "ce10f591"
   },
   "outputs": [],
   "source": [
    "x = np.array([[1,2,3]])\n",
    "y = np.array([[3,4,5]])\n",
    "print(\"Vecs:\\n\",x.T,x)\n",
    "print(\"Matrix\\n\",x.T-x)\n",
    "print(\"Matrix\\n\",y.T-y)\n",
    "\n",
    "dr2 = (x.T-x)**2 + (y.T-y)**2\n",
    "print(\"Matrix dr:\\n\",dr2)\n",
    "mass = np.array([1,2,3])\n",
    "print(\"x*m\",x * mass)\n",
    "print(\"x@m\",x @ mass)\n",
    "print(\"Matrix * m \\n\",(x.T-x) @ mass)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5abc91d1",
   "metadata": {
    "id": "5abc91d1"
   },
   "source": [
    "Now the construction above is great for creating the so called adjacency matrix. The adjancency matrix for distance can be written as\n",
    "\n",
    "$$\n",
    "r_{ij} = \\sqrt{\\Delta x_{ij}^2 + \\Delta y_{ij}^2}\n",
    "$$\n",
    "\n",
    "which has a distance for $i$ to $j$ in the i-th,j-th element, and the same distance in the j-th,i-th element. We can sum over the distances by just taking the upper triangle. We can do this through the triu  function of numpy. Let's take a quick look at how it works.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5254f134",
   "metadata": {
    "id": "5254f134"
   },
   "outputs": [],
   "source": [
    "print(\"Matrix dr:\\n\",dr2)\n",
    "print(\"Tri dr:\\n\",np.triu(dr2))\n",
    "print(\" Sum Tri dr:\\n\",np.sum(np.triu(dr2)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39ff01e0",
   "metadata": {
    "id": "39ff01e0"
   },
   "source": [
    "Alright, lets go ahead and code up everything into a new class, we call Stars. Take a look at the energy and acceleration computations, we are aiming to comput them all a the same time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d59b993",
   "metadata": {
    "id": "4d59b993"
   },
   "outputs": [],
   "source": [
    "class stars:\n",
    "    test=1\n",
    "    soften = 1e-1\n",
    "    posh = np.array([])\n",
    "    velh = np.array([])\n",
    "    toth = np.array([])\n",
    "\n",
    "    def __init__(self,imass,pos,vpos,n,isoften=1e-1):\n",
    "        self.mass = imass\n",
    "        self.rpos = pos\n",
    "        self.v    = vpos\n",
    "        self.e    = 0\n",
    "        self.n    = n\n",
    "        self.soften = isoften\n",
    "\n",
    "    def parallelAcc(self): #take in arrays of everything\n",
    "        xpos=self.rpos[:,0:1]\n",
    "        ypos=self.rpos[:,1:2]\n",
    "        dx = xpos.T - xpos\n",
    "        dy = ypos.T - ypos\n",
    "        dr2  = dx**2 + dy**2 + self.soften**2\n",
    "        dr2[dr2>0] = dr2[dr2>0]**(-1.5)\n",
    "        #idr3 = (dr2**(-1.5))\n",
    "        ax   = Gmod * (dx*dr2) @ self.mass\n",
    "        ay   = Gmod * (dy*dr2) @ self.mass\n",
    "        a = np.vstack((ax,ay))\n",
    "        self.a = a.T\n",
    "\n",
    "    def totalE(self):\n",
    "        xpos=self.rpos[:,0:1]\n",
    "        ypos=self.rpos[:,1:2]\n",
    "        dx = xpos.T - xpos\n",
    "        dy = ypos.T - ypos\n",
    "        dr = dx**2 + dy**2\n",
    "        dr = np.sqrt(dx**2 + dy**2)\n",
    "        dr[dr > 0] = 1./dr[dr > 0]\n",
    "        idr = -Gmod*self.mass.T*(self.mass*dr)\n",
    "        totalU = np.sum(np.sum(np.triu(idr)))\n",
    "        totalK = np.sum(0.5*self.mass*np.sum(self.v**2,1))\n",
    "        self.e = totalK+totalU\n",
    "\n",
    "    def firststep(self,dt):\n",
    "        self.v    = self.v   +0.5*dt*self.a\n",
    "        self.rpos = self.rpos+dt*self.v\n",
    "\n",
    "    def step(self,dt):\n",
    "        self.v    = self.v   +dt*self.a\n",
    "        self.rpos = self.rpos+dt*self.v\n",
    "        self.posh = np.append(self.posh,self.rpos)\n",
    "        self.velh = np.append(self.velh,self.v)\n",
    "        self.toth = np.append(self.toth,self.e)\n",
    "\n",
    "#Now lets setup a quick init script only for up to 4 stars\n",
    "def initparts(iN):\n",
    "    radius=1#units of AU\n",
    "    mass=1#units of Solar Mass\n",
    "    vup=circle_v(mass,radius)\n",
    "    mass = np.ones(iN)*mass # constant mass for now\n",
    "    #position\n",
    "    pos=np.array([])\n",
    "    pos  = np.append(pos,np.array([radius,0]))\n",
    "    pos  = np.append(pos,np.array([-radius,0]))\n",
    "    if iN > 2:\n",
    "        pos  = np.append(pos,np.array([0,radius]))\n",
    "    if iN > 3:\n",
    "        pos  = np.append(pos,np.array([0,-radius]))\n",
    "    #velocity\n",
    "    vel=np.array([])\n",
    "    vel  = np.append(vel,np.array([0,vup]))\n",
    "    vel  = np.append(vel,np.array([0,-vup]))\n",
    "    if iN > 2:\n",
    "        vel  = np.append(vel,np.array([-vup,0]))\n",
    "    if iN > 3:\n",
    "        vel  = np.append(vel,np.array([ vup,0]))\n",
    "    pos  = np.reshape(pos,(iN,2))\n",
    "    vel  = np.reshape(vel,(iN,2))\n",
    "    return pos,vel,mass\n",
    "\n",
    "def plotPaths(iN,xvals,evals):\n",
    "    x1vals=np.reshape(xvals,(len(evals),2*iN))\n",
    "    for i0 in np.arange(iN):\n",
    "        plt.plot(x1vals[:,2*i0],x1vals[:,2*i0+1])\n",
    "    plt.show()\n",
    "\n",
    "    plt.plot(range(len(evals)),evals,label='Total')\n",
    "    plt.legend()\n",
    "    plt.xlabel('time step')\n",
    "    plt.ylabel('energy')\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def simN2(iN=2,insteps=5):\n",
    "    dt=0.001 #units of years\n",
    "    pos,vel,mass=initparts(iN)\n",
    "    allstars = stars(mass,pos,vel,iN)\n",
    "    allstars.parallelAcc()\n",
    "    allstars.totalE()\n",
    "    allstars.firststep(dt)\n",
    "    for t in range(insteps):\n",
    "        allstars.parallelAcc()\n",
    "        allstars.totalE()\n",
    "        allstars.step(dt)\n",
    "\n",
    "    plotPaths(iN,allstars.posh,allstars.toth)\n",
    "\n",
    "simN2(2,insteps=10000)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35713652",
   "metadata": {
    "id": "35713652"
   },
   "source": [
    "Now let's setup a random init that allows for an abitrary number of stars. For this we can randomly sample over a Gaussian distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "263c3e2f",
   "metadata": {
    "id": "263c3e2f",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#Now lets setup a quick init script only for up to 4 stars\n",
    "def initparts(iN):\n",
    "    ###Lets simplify the coordinates\n",
    "    ###sample a radius along the x-axis\n",
    "    #radius=np.ones(iN)\n",
    "    #radius[0]=-1\n",
    "    radius=np.random.uniform(0.5,3,iN)#units of AU\n",
    "    radius[1]=-radius[0]\n",
    "    #theta=np.random.uniform(0,2.*np.pi,iN)\n",
    "    #merge positions and make sure each row is planet\n",
    "    theta=0\n",
    "    pos=np.vstack((radius*np.cos(theta),radius*np.sin(theta)))\n",
    "    pos=pos.T\n",
    "    #now mass\n",
    "    mass=np.random.uniform(0,1,iN)#units of Solar Mass\n",
    "    #mass=np.ones(iN)#units of Solar Mass\n",
    "    #now v\n",
    "    #v=circle_v(mass,np.abs(radius))*np.random.normal(0,3)\n",
    "    v=circle_v(mass,np.abs(radius))*np.abs(np.random.normal(0,0.1))\n",
    "    theta=np.random.uniform(0,2.*np.pi,iN)\n",
    "    v=np.vstack((v*np.cos(theta),v*np.sin(theta)))\n",
    "    v=v.T\n",
    "    #transform to the com frame\n",
    "    vcom=np.dot(mass,v)/np.sum(mass)\n",
    "    v-=vcom\n",
    "    return pos,v,mass\n",
    "\n",
    "\n",
    "\n",
    "def simN2(iN=2,insteps=5):\n",
    "    dt=0.001 #units of years\n",
    "    pos,vel,mass=initparts(iN)\n",
    "    allstars = stars(mass,pos,vel,iN)\n",
    "    allstars.parallelAcc()\n",
    "    allstars.totalE()\n",
    "    allstars.firststep(dt)\n",
    "    for t in range(insteps):\n",
    "        allstars.parallelAcc()\n",
    "        allstars.totalE()\n",
    "        allstars.step(dt)\n",
    "    plotPaths(iN,allstars.posh,allstars.toth)\n",
    "    x1vals=np.reshape(allstars.posh,(insteps,iN,2))\n",
    "    x1vals=np.swapaxes(x1vals,0,1)\n",
    "    return x1vals\n",
    "\n",
    "def animate(coords,iN=2):\n",
    "    images = []\n",
    "    fig, ax = plt.subplots(figsize=(12,7))\n",
    "    print(len(coords[0]),coords.shape)\n",
    "    for step in range(len(coords[0])-110):\n",
    "        if step % 50 == 0:\n",
    "            makePlot(iN,coords[:,step:step+100],ax,fig,images,ymin=-10,ymax=10,xmin=-10,xmax=10)\n",
    "    return images\n",
    "\n",
    "np.random.seed(109)\n",
    "xvals=simN2(4,insteps=10000)\n",
    "images=animate(xvals,iN=4)\n",
    "imageio.mimsave('orbit_4.gif', images, fps=10)\n",
    "Image(open('orbit_4.gif','rb').read())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb8f68ba",
   "metadata": {
    "id": "bb8f68ba"
   },
   "source": [
    "<a name='exercises_20_2'></a>     \n",
    "\n",
    "| [Top](#section_20_0) | [Restart Section](#section_20_2) | [Next Section](#section_20_3) |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "301a654e",
   "metadata": {
    "id": "301a654e"
   },
   "source": [
    "### <span style=\"border:3px; border-style:solid; padding: 0.15em; border-color: #90409C; color: #90409C;\">Ex-20.2.1 </span>\n",
    "\n",
    "Repeat the above setup for 100 stars using taking 1000 steps for the parallel and the old approach. Can you see how much faster this is?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d572474",
   "metadata": {
    "id": "9d572474",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import itertools\n",
    "\n",
    "def simN(iN,dt=0.001,insteps=1000):\n",
    "    combos=list(itertools.combinations(np.arange(iN), 2))\n",
    "    pos,vel,mass=initparts(iN)\n",
    "    stars=np.array([])\n",
    "    for pN in range(iN):\n",
    "        a = star(mass[pN],pos[pN,0],pos[pN,1],vel[pN,0],vel[pN,1])\n",
    "        stars = np.append(stars,a)\n",
    "    for combo in combos:\n",
    "        stars[combo[0]].force(stars[combo[1]])\n",
    "    for pStar in stars:\n",
    "        pStar.firststepv(dt)\n",
    "    for t in range(insteps):\n",
    "        for combo in combos:\n",
    "            stars[combo[0]].force(stars[combo[1]])\n",
    "            stars[combo[0]].potential(stars[combo[1]])\n",
    "        for pStar in stars:\n",
    "            pStar.step(dt)\n",
    "\n",
    "    totalE=np.zeros(insteps)\n",
    "    for i0 in np.arange(iN):\n",
    "        x1vals=np.reshape(stars[i0].posh,(len(stars[i0].posh)//2,2))\n",
    "        plt.plot(x1vals[:,0],x1vals[:,1])\n",
    "        totalE += (stars[i0].poth+stars[i0].kinh)\n",
    "    plt.show()\n",
    "    plt.plot(range(insteps),totalE,label='Total')\n",
    "    plt.legend()\n",
    "    plt.xlabel('time step')\n",
    "    plt.ylabel('energy')\n",
    "    plt.show()\n",
    "    return\n",
    "\n",
    "import time\n",
    "print(\"Start Basic:\")\n",
    "start_time = time.time()\n",
    "xvals=simN(100,insteps=100)\n",
    "print(\"Stop Basic --- %s seconds ---\" % (time.time() - start_time))\n",
    "\n",
    "print(\"Start Parallel\")\n",
    "start_time = time.time()\n",
    "xvals=simN2(100,insteps=100)\n",
    "print(\"Stop Parallel --- %s seconds ---\" % (time.time() - start_time))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78c01013",
   "metadata": {
    "id": "78c01013"
   },
   "source": [
    "<div style=\"border:1.5px; border-style:solid; padding: 0.5em; border-color: #90409C; color: #90409C;\">\n",
    "\n",
    "**SOLUTION:**\n",
    "\n",
    "<pre>\n",
    "\n",
    "</pre>\n",
    "        \n",
    "**EXPLANATION:**\n",
    "\n",
    "    \n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dc79cec",
   "metadata": {
    "id": "4dc79cec"
   },
   "source": [
    "<a name='section_20_3'></a>\n",
    "<hr style=\"height: 1px;\">\n",
    "\n",
    "## <h2 style=\"border:1px; border-style:solid; padding: 0.25em; color: #FFFFFF; background-color: #90409C\">L20.3 3-body Problem</h2>  \n",
    "\n",
    "| [Top](#section_20_0) | [Previous Section](#section_20_2) | [Exercises](#exercises_20_3) | [Next Section](#section_20_4) |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa440e9f",
   "metadata": {
    "id": "fa440e9f"
   },
   "source": [
    "<h3>Overview</h3>\n",
    "\n",
    "Now that we have a setup that works well, lets take some time to explore the 3-body problem. Here, we can look at the dynamics and have a little fun, to see how motion works with 3-bodies involved. Let's consider a few 3-body situations and look at the motion we have with our numrical simulation.\n",
    "\n",
    "Its fun to play with these solutions since there is a wide variety of solution that are possible."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6fe56a2",
   "metadata": {
    "id": "b6fe56a2",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#Now lets setup a quick init script only for up to 4 stars\n",
    "def init3body(iN):\n",
    "    radius = np.ones(iN)\n",
    "    #radius=np.random.uniform(0.5,3,iN)#units of AU\n",
    "    #theta=np.random.uniform(0,2.*np.pi,iN)\n",
    "    #merge positions and make sure each row is planet\n",
    "    theta = np.arange(0,2*np.pi,2*np.pi/iN)\n",
    "    pos=np.vstack((radius*np.cos(theta),radius*np.sin(theta)))\n",
    "    pos=pos.T\n",
    "    #now mass\n",
    "    #mass=np.random.uniform(0,1,iN)#units of Solar Mass\n",
    "    mass=np.ones(iN)#units of Solar Mass\n",
    "    #now v\n",
    "    v=circle_v(mass,np.abs(radius))*1.5\n",
    "    theta+=np.pi/2.\n",
    "    #v=np.zeros(iN)\n",
    "    #theta=np.random.uniform(0,2.*np.pi,iN)\n",
    "    v=np.vstack((v*np.cos(theta),v*np.sin(theta)))\n",
    "    v=v.T\n",
    "    #transform to the com frame\n",
    "    vcom=np.dot(mass,v)/np.sum(mass)\n",
    "    v-=vcom\n",
    "    return pos,v,mass\n",
    "\n",
    "\n",
    "\n",
    "def simN2(iN=3,insteps=5):\n",
    "    dt=0.001 #units of years\n",
    "    pos,vel,mass=init3body(iN)\n",
    "    allstars = stars(mass,pos,vel,iN)\n",
    "    allstars.parallelAcc()\n",
    "    allstars.totalE()\n",
    "    allstars.firststep(dt)\n",
    "    for t in range(insteps):\n",
    "        allstars.parallelAcc()\n",
    "        allstars.totalE()\n",
    "        allstars.step(dt)\n",
    "    plotPaths(iN,allstars.posh,allstars.toth)\n",
    "    x1vals=np.reshape(allstars.posh,(insteps,iN,2))\n",
    "    x1vals=np.swapaxes(x1vals,0,1)\n",
    "    print(x1vals.shape)\n",
    "    return x1vals\n",
    "\n",
    "def animate(coords,iN=2):\n",
    "    images = []\n",
    "    fig, ax = plt.subplots(figsize=(12,7))\n",
    "    print(len(coords[0]),coords.shape)\n",
    "    for step in range(len(coords[0])-110):\n",
    "        if step % 50 == 0:\n",
    "            makePlot(iN,coords[:,step:step+100],ax,fig,images,ymin=-3,ymax=3,xmin=-3,xmax=3)\n",
    "    return images\n",
    "\n",
    "\n",
    "xvals=simN2(3,insteps=10000)\n",
    "images=animate(xvals,iN=3)\n",
    "imageio.mimsave('orbit_3.gif', images, fps=10)\n",
    "Image(open('orbit_3.gif','rb').read())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fc4d1d1",
   "metadata": {
    "id": "0fc4d1d1",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#Now lets setup a quick init script only for up to 4 stars\n",
    "def init3body(iN):\n",
    "    radius = np.ones(iN)\n",
    "    #radius=np.random.uniform(0.5,3,iN)#units of AU\n",
    "    #theta=np.random.uniform(0,2.*np.pi,iN)\n",
    "    #merge positions and make sure each row is planet\n",
    "    theta = np.arange(0,2*np.pi,2*np.pi/iN)\n",
    "    pos=np.vstack((radius*np.cos(theta),radius*np.sin(theta)))\n",
    "    pos=pos.T\n",
    "    #now mass\n",
    "    #mass=np.random.uniform(0,1,iN)#units of Solar Mass\n",
    "    mass=np.ones(iN)#units of Solar Mass\n",
    "    #now v\n",
    "    v=circle_v(mass,np.abs(radius))*1.3\n",
    "    theta+=np.pi/2.\n",
    "    #v=np.zeros(iN)\n",
    "    #theta=np.random.uniform(0,2.*np.pi,iN)\n",
    "    v=np.vstack((v*np.cos(theta),v*np.sin(theta)))\n",
    "    v=v.T\n",
    "    #transform to the com frame\n",
    "    vcom=np.dot(mass,v)/np.sum(mass)\n",
    "    v-=vcom\n",
    "    return pos,v,mass\n",
    "\n",
    "\n",
    "#np.random.seed(300)\n",
    "xvals=simN2(3,insteps=10000)\n",
    "images=animate(xvals,iN=3)\n",
    "imageio.mimsave('orbit_3_v1.gif', images, fps=10)\n",
    "Image(open('orbit_3_v1.gif','rb').read())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dd4cb8b",
   "metadata": {
    "id": "1dd4cb8b",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#Now lets setup a quick init script only for up to 4 stars\n",
    "def init3body(iN):\n",
    "    radius = np.ones(iN)\n",
    "    #radius=np.random.uniform(0.5,3,iN)#units of AU\n",
    "    #theta=np.random.uniform(0,2.*np.pi,iN)\n",
    "    #merge positions and make sure each row is planet\n",
    "    theta = np.arange(0,2*np.pi,2*np.pi/iN)\n",
    "    pos=np.vstack((radius*np.cos(theta),radius*np.sin(theta)))\n",
    "    pos=pos.T\n",
    "    #now mass\n",
    "    #mass=np.random.uniform(0,1,iN)#units of Solar Mass\n",
    "    mass=np.ones(iN)#units of Solar Mass\n",
    "    #now v\n",
    "    v=circle_v(mass,np.abs(radius))*2.0\n",
    "    theta+=np.pi/2.\n",
    "    #v=np.zeros(iN)\n",
    "    #theta=np.random.uniform(0,2.*np.pi,iN)\n",
    "    v=np.vstack((v*np.cos(theta),v*np.sin(theta)))\n",
    "    v=v.T\n",
    "    #transform to the com frame\n",
    "    vcom=np.dot(mass,v)/np.sum(mass)\n",
    "    v-=vcom\n",
    "    return pos,v,mass\n",
    "\n",
    "def animate(coords,iN=2,ymin=-10,ymax=10,xmin=-10,xmax=10,stepsize=50):\n",
    "    images = []\n",
    "    fig, ax = plt.subplots(figsize=(12,7))\n",
    "    for step in range(len(coords[0])-110):\n",
    "        if step % stepsize == 0:\n",
    "            makePlot(iN,coords[:,step:step+100],ax,fig,images,ymin=ymin,ymax=ymax,xmin=xmin,xmax=xmax)\n",
    "    return images\n",
    "\n",
    "xvals=simN2(3,insteps=10000)\n",
    "images=animate(xvals,iN=3)\n",
    "imageio.mimsave('orbit_3_v2.gif', images, fps=10)\n",
    "Image(open('orbit_3_v2.gif','rb').read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cecbc0f4",
   "metadata": {
    "id": "cecbc0f4"
   },
   "outputs": [],
   "source": [
    "#Now lets setup a quick init script only for up to 4 stars\n",
    "def init3body(iN,scale):\n",
    "    radius = np.ones(iN)\n",
    "    #radius=np.random.uniform(0.5,3,iN)#units of AU\n",
    "    #theta=np.random.uniform(0,2.*np.pi,iN)\n",
    "    #merge positions and make sure each row is planet\n",
    "    theta = np.arange(0,2*np.pi,2*np.pi/iN)\n",
    "    pos=np.vstack((radius*np.cos(theta),radius*np.sin(theta)))\n",
    "    pos=pos.T\n",
    "    #now mass\n",
    "    #mass=np.random.uniform(0,1,iN)#units of Solar Mass\n",
    "    mass=np.ones(iN)#units of Solar Mass\n",
    "    #now v\n",
    "    v=circle_v(mass,np.abs(radius))*scale\n",
    "    theta+=np.pi/2.\n",
    "    #v=np.zeros(iN)\n",
    "    #theta=np.random.uniform(0,2.*np.pi,iN)\n",
    "    v=np.vstack((v*np.cos(theta),v*np.sin(theta)))\n",
    "    v=v.T\n",
    "    #transform to the com frame\n",
    "    vcom=np.dot(mass,v)/np.sum(mass)\n",
    "    v-=vcom\n",
    "    return pos,v,mass\n",
    "\n",
    "def plotJustPaths(iN,xvals,evals):\n",
    "    x1vals=np.reshape(xvals,(len(evals),2*iN))\n",
    "    for i0 in np.arange(iN):\n",
    "        plt.plot(x1vals[:,2*i0],x1vals[:,2*i0+1])\n",
    "\n",
    "\n",
    "def simInit(iN=3,insteps=5,scale=1.0):\n",
    "    dt=0.001 #units of years\n",
    "    pos,vel,mass=init3body(iN,scale)\n",
    "    allstars = stars(mass,pos,vel,iN)\n",
    "    allstars.parallelAcc()\n",
    "    allstars.totalE()\n",
    "    allstars.firststep(dt)\n",
    "    for t in range(insteps):\n",
    "        allstars.parallelAcc()\n",
    "        allstars.totalE()\n",
    "        allstars.step(dt)\n",
    "    plotJustPaths(iN,allstars.posh,allstars.toth)\n",
    "    x1vals=np.reshape(allstars.posh,(insteps,iN,2))\n",
    "    x1vals=np.swapaxes(x1vals,0,1)\n",
    "    return x1vals\n",
    "\n",
    "for scale in np.arange(0.5,2.5,0.1):\n",
    "    x1vals=simInit(3,5000,scale)\n",
    "\n",
    "plt.xlim(-10,10)\n",
    "plt.ylim(-10,10)\n",
    "plt.xlabel(\"x[AU]\")\n",
    "plt.ylabel(\"x[AU]\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bf6b5ce",
   "metadata": {
    "id": "1bf6b5ce"
   },
   "source": [
    "Now for fun, lets consider a system like the earth and sun setup, and we can try to put a light planet aorund and solve for the motion in a vareity of forms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e39f53a",
   "metadata": {
    "id": "4e39f53a",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#Now lets setup a quick init script only for up to 4 stars\n",
    "def init3body(iN,scale):\n",
    "    radius = np.ones(iN)\n",
    "    radius[0] = 0.0001\n",
    "    #radius=np.random.uniform(0.5,3,iN)#units of AU\n",
    "    #theta=np.random.uniform(0,2.*np.pi,iN)\n",
    "    #merge positions and make sure each row is planet\n",
    "    theta = np.arange(0,2*np.pi,2*np.pi/iN)\n",
    "    theta[0] = 0\n",
    "    theta[1] = 0\n",
    "    theta[2] = np.pi*0.5\n",
    "    pos=np.vstack((radius*np.cos(theta),radius*np.sin(theta)))\n",
    "    pos=pos.T\n",
    "    #now mass\n",
    "    #mass=np.random.uniform(0,1,iN)#units of Solar Mass\n",
    "    mass=np.ones(iN)#units of Solar Mass\n",
    "    mass[1] *= 0.01\n",
    "    mass[2] *= 0.001\n",
    "    #now v\n",
    "    mr = np.ones(iN)\n",
    "    v=circle_v(mr,np.abs(radius*0.25))\n",
    "    theta+=np.pi/2.\n",
    "    v[0] = 0\n",
    "    #v=np.zeros(iN)\n",
    "    #theta=np.random.uniform(0,2.*np.pi,iN)\n",
    "    v=np.vstack((v*np.cos(theta),v*np.sin(theta)))\n",
    "    v=v.T\n",
    "    print(v)\n",
    "    #transform to the com frame\n",
    "    vcom=np.dot(mass,v)/np.sum(mass)\n",
    "    v-=vcom\n",
    "    print(vcom)\n",
    "    return pos,v,mass\n",
    "\n",
    "def plotJustPaths(iN,xvals,evals):\n",
    "    x1vals=np.reshape(xvals,(len(evals),2*iN))\n",
    "    for i0 in np.arange(iN):\n",
    "        plt.plot(x1vals[:,2*i0],x1vals[:,2*i0+1])\n",
    "\n",
    "\n",
    "def simInit(iN=3,insteps=5,scale=1.0):\n",
    "    dt=0.001 #units of years\n",
    "    pos,vel,mass=init3body(iN,scale)\n",
    "    allstars = stars(mass,pos,vel,iN)\n",
    "    allstars.parallelAcc()\n",
    "    allstars.totalE()\n",
    "    allstars.firststep(dt)\n",
    "    for t in range(insteps):\n",
    "        allstars.parallelAcc()\n",
    "        allstars.totalE()\n",
    "        allstars.step(dt)\n",
    "    plotJustPaths(iN,allstars.posh,allstars.toth)\n",
    "    x1vals=np.reshape(allstars.posh,(insteps,iN,2))\n",
    "    x1vals=np.swapaxes(x1vals,0,1)\n",
    "    return x1vals\n",
    "\n",
    "x1vals=simInit(3,5000,1)\n",
    "\n",
    "plt.xlim(-2,2)\n",
    "plt.ylim(-2,2)\n",
    "plt.xlabel(\"x[AU]\")\n",
    "plt.ylabel(\"x[AU]\")\n",
    "plt.show()\n",
    "\n",
    "images=animate(x1vals,iN=3,ymin=-2,ymax=2,xmin=-2,xmax=2)\n",
    "imageio.mimsave('orbit_3_v3.gif', images, fps=10)\n",
    "Image(open('orbit_3_v3.gif','rb').read())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a41c0a13",
   "metadata": {
    "id": "a41c0a13"
   },
   "source": [
    "<a name='exercises_20_3'></a>     \n",
    "\n",
    "| [Top](#section_20_0) | [Restart Section](#section_20_3) | [Next Section](#section_20_4) |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c60eebf",
   "metadata": {
    "id": "4c60eebf"
   },
   "source": [
    "### <span style=\"border:3px; border-style:solid; padding: 0.15em; border-color: #90409C; color: #90409C;\">Ex-20.3.1 </span>\n",
    "\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "903f0dab",
   "metadata": {
    "id": "903f0dab"
   },
   "source": [
    "<a name='section_20_4'></a>\n",
    "<hr style=\"height: 1px;\">\n",
    "\n",
    "## <h2 style=\"border:1px; border-style:solid; padding: 0.25em; color: #FFFFFF; background-color: #90409C\">L20.4 N-body Problem</h2>  \n",
    "\n",
    "| [Top](#section_20_0) | [Previous Section](#section_20_3) | [Exercises](#exercises_20_4) | [Next Section](#section_20_5) |\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "938046e6",
   "metadata": {
    "id": "938046e6"
   },
   "source": [
    "<h3>Overview</h3>\n",
    "\n",
    "Now, we have been able to scale our simulation so that it can work pretty well on $mathcal{O}(100)$ different planets. However, we would really to make a setup that can capture the dynamics for 1000s of bodies of stars. Something that we could potentially use to model our galaxy?\n",
    "\n",
    "By going to larger and larger numbers of stars, we can start to capture the full dynamics present when we perform large scale astronomical simulations. The problem with going to larger and larger number of stars is that we know have more and more pairwise computations to compute the force.  Simply put the force on a single body is :\n",
    "\n",
    "$$\n",
    "\\vec{a}_{i} = \\sum_{j} \\frac{G M_{j}}{|\\vec{r}_{j}-\\vec{r}_{i}|^{3}}\\left(\\vec{r}_{i}-\\vec{r}_{j}\\right)\n",
    "$$\n",
    "\n",
    "Which requires a sum over $j \\in N_{\\rm body}$.  Computing this for all values $i\\in N_{\\rm body}$ gives us a computation that scales as $\\mathcal{N_{\\rm body}^2}$. Which means that for $N_{\\rm body}=1000$, we are talking about a computation that is $\\mathcal{O}(10^{6})$ in computations.\n",
    "\n",
    "Now an important point that should be made with large scale stellar simulations is the notion of timescale. We we have two masses that are very far apart, the amount of updates that need to happen is much smaller than if we have two masses that are nearby. The point being that stars that all have roughly the velocity the time updates will impact the local dynamics when $r$ is small compared to large $r$. We can then write a time update as :\n",
    "\n",
    "$$\n",
    "\\Delta t \\propto \\frac{\\Delta v_{ij}}{\\Delta r_{ij}} \\\\\n",
    "\\Delta t \\propto \\frac{1}{\\Delta r_{ij}}\n",
    "$$\n",
    "\n",
    "and in practice the velocities are typically very simlar on large scales, so this yields us to the second equation. Now conceptually, we can also think of the length scale as a way to resolve various tiers of resolution in n-body computations. What I mean is that we can imagine instead of computing the individual forces of many stars that are far away, we can average the mass and the distances and following Gauss's law treat these as a single particle with a combined mass given by the sum of the stars.\n",
    "\n",
    "Practically speaking this makes our summation over the points given by\n",
    "\n",
    "$$\n",
    "\\vec{a}_{i} = \\sum_{j \\in \\Delta r < \\Delta} \\frac{G M_{j}}{|\\vec{r}_{j}-\\vec{r}_{i}|^{3}}\\left(\\vec{r}_{i}-\\vec{r}_{j}\\right) + \\frac{G \\sum_{j \\in r > \\Delta} m_{j}} { |\\vec{r}_{i}-\\sum_{j \\in r > \\Delta} m_{j}\\vec{r_{j}}|^{3}} \\left(\\vec{r}_{i}-\\sum_{j \\in r > \\Delta} m_{j}\\vec{r_{j}}\\right)\n",
    "$$\n",
    "\n",
    "In other words for distances larger than some value $\\Delta$ we just sum over all the stars and compute the average distances to that point.\n",
    "\n",
    "Now to dermine a reasonable average, the way we approach this is by building a tree structure, this is often done by building a [k-d tree](https://en.wikipedia.org/wiki/K-d_treek-d).  This tree will take an image, subdivide into two subimages, then take each sub image and subdivide it and so on. Lets take a look at how it looks.\n",
    "\n",
    "Before we go the whole way, lets just play with a 1D dataset to see how it works"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c100e30d",
   "metadata": {
    "id": "c100e30d"
   },
   "outputs": [],
   "source": [
    "xarr = np.random.random((10, 1)) * 2 - 1\n",
    "print(xarr)\n",
    "print(\"Max:\",np.argmax(xarr))\n",
    "print(\"Sort:\",np.argsort(xarr,axis=0))\n",
    "xarr=xarr[np.argsort(xarr,axis=0)]\n",
    "print(\"half:\",xarr[xarr.shape[0]//2])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f656dcc",
   "metadata": {
    "id": "9f656dcc"
   },
   "source": [
    "From this, we can start to take an array and divide it into subsets. by splitting the x or y position of the samples. In light of this, lets make a KDTree that starts to cut the data into two using either the y or the x-axis. We will make this tree recursive, so that we recurse lower and lower within the tree."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "996ef316",
   "metadata": {
    "id": "996ef316"
   },
   "outputs": [],
   "source": [
    "class KDTree:\n",
    "    \"\"\"Simple KD tree class\"\"\"\n",
    "\n",
    "    # class initialization function\n",
    "    def __init__(self, data, mins, maxs):\n",
    "        self.data = np.asarray(data)\n",
    "\n",
    "        # data should be two-dimensional\n",
    "        assert self.data.shape[1] == 2\n",
    "\n",
    "        if mins is None:\n",
    "            mins = data.min(0)\n",
    "        if maxs is None:\n",
    "            maxs = data.max(0)\n",
    "\n",
    "        self.mins  = np.asarray(mins)\n",
    "        self.maxs  = np.asarray(maxs)\n",
    "        self.sizes = self.maxs - self.mins\n",
    "\n",
    "        self.child1 = None\n",
    "        self.child2 = None\n",
    "\n",
    "        if len(data) > 1:\n",
    "            # sort on the dimension with the largest spread\n",
    "            largest_dim  = np.argmax(self.sizes)\n",
    "            i_sort       = np.argsort(self.data[:, largest_dim])\n",
    "            self.data[:] = self.data[i_sort, :]\n",
    "\n",
    "            # find split point\n",
    "            N = self.data.shape[0]\n",
    "            half_N = int(N / 2)\n",
    "            split_point = 0.5 * (self.data[half_N, largest_dim] + self.data[half_N - 1, largest_dim])\n",
    "\n",
    "            # create subnodes\n",
    "            mins1 = self.mins.copy()\n",
    "            mins1[largest_dim] = split_point\n",
    "            maxs2 = self.maxs.copy()\n",
    "            maxs2[largest_dim] = split_point\n",
    "\n",
    "            # Recursively build a KD-tree on each sub-node\n",
    "            self.child1 = KDTree(self.data[half_N:], mins1, self.maxs)\n",
    "            self.child2 = KDTree(self.data[:half_N], self.mins, maxs2)\n",
    "\n",
    "    def draw_rectangle(self, ax, depth=None):\n",
    "        \"\"\"Recursively plot a visualization of the KD tree region\"\"\"\n",
    "        if depth == 0:\n",
    "            rect = plt.Rectangle(self.mins, *self.sizes, ec='k', fc='none')\n",
    "            ax.add_patch(rect)\n",
    "\n",
    "        if self.child1 is not None:\n",
    "            if depth is None:\n",
    "                self.child1.draw_rectangle(ax)\n",
    "                self.child2.draw_rectangle(ax)\n",
    "            elif depth > 0:\n",
    "                self.child1.draw_rectangle(ax, depth - 1)\n",
    "                self.child2.draw_rectangle(ax, depth - 1)\n",
    "\n",
    "\n",
    "#------------------------------------------------------------\n",
    "# Create a set of structured random points in two dimensions\n",
    "np.random.seed(0)\n",
    "\n",
    "X = np.random.random((30, 2)) * 2 - 1\n",
    "X[:, 1] *= 0.1\n",
    "X[:, 1] += X[:, 0] ** 2 #y=x^2\n",
    "\n",
    "#------------------------------------------------------------\n",
    "# Use our KD Tree class to recursively divide the space\n",
    "KDT = KDTree(X, [-1.1, -0.1], [1.1, 1.1])\n",
    "\n",
    "#------------------------------------------------------------\n",
    "# Plot four different levels of the KD tree\n",
    "fig = plt.figure(figsize=(10, 10))\n",
    "fig.subplots_adjust(wspace=0.1, hspace=0.15,left=0.1, right=0.9, bottom=0.05, top=0.9)\n",
    "\n",
    "for level in range(1, 5):\n",
    "    ax = fig.add_subplot(2, 2, level)#, xticks=[], yticks=[])\n",
    "    ax.scatter(X[:, 0], X[:, 1], s=9)\n",
    "    KDT.draw_rectangle(ax, depth=level - 1)\n",
    "\n",
    "    ax.set_xlim(-1.2, 1.2)\n",
    "    ax.set_ylim(-0.15, 1.15)\n",
    "    ax.set_title('level %i' % level)\n",
    "\n",
    "# suptitle() adds a title to the entire figure\n",
    "fig.suptitle('$k$d-tree Example')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adad3d01",
   "metadata": {
    "id": "adad3d01"
   },
   "source": [
    "Now for a specific point. What we can now do is use this tree structure to merge elements into a single object. The way we will do this is to split stars.\n",
    "\n",
    "The problem with the above is that while this tree splits the data by the density of the points, it requires that we sort the dataset so that we can split it into smaller datasets. Do you understand why this could be a problem?\n",
    "​\n",
    "Sort requires pairwise comparisons. This is a $\\mathcal{O}(n^{2})$, and it defeats the point of trying to avoid the large $N$ set of comparisons. Hence, we can't actually sort along this direction, we need to just geometrically divide this space using the full range of the system.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33104153",
   "metadata": {
    "id": "33104153"
   },
   "outputs": [],
   "source": [
    "class SquareTree:\n",
    "    \"\"\"KD Tree aimed\"\"\"\n",
    "\n",
    "    # class initialization function\n",
    "    def __init__(self,iMins,iMaxs,iAxis=0,idepth=0):\n",
    "        self.m     = 0\n",
    "        self.depth = idepth+1\n",
    "        self.mins=iMins\n",
    "        self.maxs=iMaxs\n",
    "        self.dxs = self.maxs - self.mins\n",
    "        self.mass   = 0\n",
    "        self.posm   = np.array([0,0])\n",
    "        self.pos    = np.array([0,0])\n",
    "        self.child1 = None\n",
    "        self.child2 = None\n",
    "        minsR = self.mins.copy()\n",
    "        maxsL = self.maxs.copy()\n",
    "        #iterative funciton that defines the splitting\n",
    "        if self.depth > 6: #6 levels deep\n",
    "            return\n",
    "        oAxis=1 #alternate x and y-axis (don't need to BTW)\n",
    "        if iAxis == 1:\n",
    "            oAxis = 0\n",
    "        maxsL[iAxis]=iMaxs[iAxis]-self.dxs[iAxis]*0.5 #Now split the range between left and right in physical half\n",
    "        minsR[iAxis]=iMins[iAxis]+self.dxs[iAxis]*0.5 # li\n",
    "        self.child1 = SquareTree(self.mins,maxsL,oAxis,self.depth)\n",
    "        self.child2 = SquareTree(minsR,self.maxs,oAxis,self.depth)\n",
    "\n",
    "    def draw_rectangle(self, ax, depth=None):\n",
    "        if depth == 0:\n",
    "            rect = plt.Rectangle(self.mins, *self.dxs, ec='k', fc='none')\n",
    "            ax.add_patch(rect)\n",
    "\n",
    "        if self.child1 is not None:\n",
    "            if depth is None:\n",
    "                self.child1.draw_rectangle(ax)\n",
    "                self.child2.draw_rectangle(ax)\n",
    "            elif depth > 0:\n",
    "                self.child1.draw_rectangle(ax, depth - 1)\n",
    "                self.child2.draw_rectangle(ax, depth - 1)\n",
    "\n",
    "\n",
    "#now lets make a star object that stpes\n",
    "class body():\n",
    "    def __init__(self, ipos, ivpos, imass):\n",
    "        self.rpos = ipos\n",
    "        self.v    = ivpos\n",
    "        self.mass = imass\n",
    "        self.a    = np.array([0,0])\n",
    "\n",
    "    def firststep(self,dt):\n",
    "        self.v=self.v   +0.5*dt*self.a\n",
    "        self.rpos=self.rpos+dt*self.v\n",
    "\n",
    "    def step(self,dt):\n",
    "        #vnew = self.v   +dt*self.a\n",
    "        #self.rpos=self.rpos+dt*self.v\n",
    "        #self.v   =vnew\n",
    "        self.v    = self.v   +dt*self.a\n",
    "        self.rpos = self.rpos+dt*self.v\n",
    "\n",
    "\n",
    "def grid(iX):\n",
    "    Xmin = np.min(iX,axis=0)\n",
    "    Xmax = np.max(iX,axis=0)\n",
    "    SQT  = SquareTree(Xmin,Xmax,0)\n",
    "    return SQT\n",
    "\n",
    "def points(iBodies):\n",
    "    lXs = np.array([])\n",
    "    for pBody in iBodies:\n",
    "        lXs = np.append(lXs,pBody.rpos)\n",
    "    lXs = np.reshape(lXs,(len(iBodies),2))\n",
    "    return lXs\n",
    "\n",
    "\n",
    "#First we will sample 3000 stars in 2D space with 2D velocity\n",
    "np.random.seed(1234)\n",
    "X = np.random.random((30, 2)) * 2 - 1\n",
    "V = np.random.random((30, 2)) * 0.1\n",
    "#X[:, 1] *= 0.1\n",
    "#X[:, 1] += X[:, 0] ** 2\n",
    "bodies = []\n",
    "for i0 in range(len(X)):\n",
    "    mass=1. # they will all have a mass of a solar mass\n",
    "    pBody = body(X[i0],V[i0],mass)\n",
    "    bodies.append(pBody)\n",
    "\n",
    "lXs = points(bodies)\n",
    "SQT = grid(lXs)\n",
    "fig1 = plt.figure(figsize=(10, 10))\n",
    "fig1.subplots_adjust(wspace=0.1, hspace=0.15,left=0.1, right=0.9,bottom=0.05, top=0.9)\n",
    "for level in range(1, 6):\n",
    "    ax = fig1.add_subplot(2, 3, level)\n",
    "    ax.scatter(lXs[:, 0], lXs[:, 1], s=9)\n",
    "    SQT.draw_rectangle(ax, depth=level)\n",
    "    ax.set_xlim(-2, 2)\n",
    "    ax.set_ylim(-2, 2)\n",
    "    ax.set_title('level %i' % level)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06dc54cd",
   "metadata": {
    "id": "06dc54cd"
   },
   "source": [
    "Once we have this structure, what we can do is fill it with all of our objects, and then we can compute the force by constructing a force law that relies on grid values for things that are far away and positions for things that are close.\n",
    "\n",
    "For this, our we can define our force law as:\n",
    "\n",
    "$$\n",
    "\\vec{a_{i}} = G\\frac{\\sum_{j\\in grid} m_{j}} {|\\vec{r}_{i}-\\frac{1}{m_{\\rm tot}}\\sum_{j\\in grid} m_{j}\\vec{r}_{j}|^{3}} \\left(\\vec{r_{i}}-\\frac{1}{m_{\\rm tot}}\\sum_{j\\in grid} \\vec{m_{j} r_{j}}\\right)\n",
    "$$\n",
    "\n",
    "What this means is that when we populate the grid, we need to compute two things\n",
    "\n",
    "$$\n",
    "m_{\\rm tot}^{grid}=\\sum_{j\\in grid} m_{j} \\\\\n",
    "r_{\\rm tot}^{grid}=\\frac{1}{m_{\\rm tot}^{grid}} \\sum_{j\\in grid} m_{j}\\vec{r_{j}} \\\\\n",
    "$$\n",
    "\n",
    "This allows us to define two new functions to our tree that keep track of the mass and teh acceleration after, we ahve defined teh grid.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98dbbf5d",
   "metadata": {
    "id": "98dbbf5d",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "class SquareTree:\n",
    "    \"\"\"KD Tree aimed\"\"\"\n",
    "\n",
    "    # class initialization function\n",
    "    def __init__(self,iMins,iMaxs,iAxis=0,idepth=0,isoften=1e-1):\n",
    "        self.m      = 0\n",
    "        self.depth  = idepth+1\n",
    "        self.mins   = iMins\n",
    "        self.maxs   = iMaxs\n",
    "        self.dxs    = self.maxs - self.mins\n",
    "        self.mass   = 0\n",
    "        self.posm   = np.array([0.,0.])\n",
    "        self.pos    = np.array([0.,0.])\n",
    "        self.soften = isoften\n",
    "        self.maxdepth=6\n",
    "        self.child1 = None\n",
    "        self.child2 = None\n",
    "        minsR = self.mins.copy()\n",
    "        maxsL = self.maxs.copy()\n",
    "        #iterative funciton that defines the splitting\n",
    "        if self.depth > self.maxdepth: #6 levels deep\n",
    "            return\n",
    "        oAxis=1 #alternate x and y-axis (don't need to BTW)\n",
    "        if iAxis == 1:\n",
    "            oAxis = 0\n",
    "        maxsL[iAxis]=iMaxs[iAxis]-self.dxs[iAxis]*0.5 #Now split the range between left and right in physical half\n",
    "        minsR[iAxis]=iMins[iAxis]+self.dxs[iAxis]*0.5 # li\n",
    "        self.child1 = SquareTree(self.mins,maxsL,oAxis,self.depth,self.soften)\n",
    "        self.child2 = SquareTree(minsR,self.maxs,oAxis,self.depth,self.soften)\n",
    "\n",
    "    def addmass(self,mass,pos):\n",
    "        #compute for whole grid\n",
    "        self.m    += mass\n",
    "        self.posm += mass*pos #intermediate value\n",
    "        self.pos   = self.posm/self.m #mass weighted avg\n",
    "        #compute it for the children\n",
    "        if self.child1 == None:\n",
    "            return\n",
    "        if pos[0] <= self.child1.maxs[0] and pos[1] <= self.child1.maxs[1]:\n",
    "            self.child1.addmass(mass,pos)\n",
    "        else:\n",
    "            self.child2.addmass(mass,pos)\n",
    "\n",
    "    def accel(self,pos):\n",
    "        #compute it for the grid\n",
    "        if self.m == 0:\n",
    "            return 0\n",
    "        #compute the fine grained resolution if distance > x\n",
    "        if self.dist(pos)/(np.max(self.dxs)**2) < 4 and self.depth < self.maxdepth:\n",
    "            a1 = self.child1.accel(pos)\n",
    "            a2 = self.child2.accel(pos)\n",
    "            return a1+a2\n",
    "        else:# compute the coarse grain guy\n",
    "            dx  = self.pos-pos\n",
    "            dx3 = (np.dot(dx,dx)+self.soften**2)**(-1.5)\n",
    "            return Gmod*self.m*dx*dx3\n",
    "\n",
    "    def dist(self,pos):\n",
    "        #distance to grid center\n",
    "        dx  = self.pos-pos\n",
    "        return np.dot(dx,dx)\n",
    "\n",
    "    def draw_rectangle(self, ax, depth=None):\n",
    "        if depth == 0:\n",
    "            rect = plt.Rectangle(self.mins, *self.dxs, ec='k', fc='none')\n",
    "            ax.add_patch(rect)\n",
    "\n",
    "        if self.child1 is not None:\n",
    "            if depth is None:\n",
    "                self.child1.draw_rectangle(ax)\n",
    "                self.child2.draw_rectangle(ax)\n",
    "            elif depth > 0:\n",
    "                self.child1.draw_rectangle(ax, depth - 1)\n",
    "                self.child2.draw_rectangle(ax, depth - 1)\n",
    "\n",
    "\n",
    "class TreeStars:\n",
    "    def __init__(self,iBodies,iX,iAxis=0,idepth=0,isoften=1e-1):\n",
    "        Xmin = np.min(iX,axis=0)\n",
    "        Xmax = np.max(iX,axis=0)\n",
    "        self.posh   = np.array([])\n",
    "        self.grid   = SquareTree(Xmin,Xmax,0,idepth=0,isoften=isoften)\n",
    "        self.bodies = iBodies\n",
    "        self.nsteps = 0\n",
    "\n",
    "    def addMass(self):\n",
    "        for pBody in self.bodies:\n",
    "            self.grid.addmass(pBody.mass,pBody.rpos)\n",
    "\n",
    "    def force(self):\n",
    "        for pBody in self.bodies:\n",
    "            pBody.a = self.grid.accel(pBody.rpos)\n",
    "\n",
    "    def firststep(self,dt):\n",
    "        for pBody in self.bodies:\n",
    "            pBody.firststep(dt)\n",
    "\n",
    "    def step(self,dt):\n",
    "        for pBody in self.bodies:\n",
    "            pBody.step(dt)\n",
    "\n",
    "    def points(self):\n",
    "        lXs = np.array([])\n",
    "        for pBody in self.bodies:\n",
    "            lXs = np.append(lXs,pBody.rpos)\n",
    "        lXs = np.reshape(lXs,(len(self.bodies),2))\n",
    "        return lXs\n",
    "\n",
    "    def store(self):\n",
    "        lXs = self.points()\n",
    "        self.posh = np.append(self.posh,lXs)\n",
    "\n",
    "    def history(self):\n",
    "        return np.reshape(self.posh,(self.nsteps,len(self.bodies),2))\n",
    "\n",
    "    def regrid(self):\n",
    "        lX = self.points()\n",
    "        Xmin = np.min(lX,axis=0)\n",
    "        Xmax = np.max(lX,axis=0)\n",
    "        self.grid  = SquareTree(Xmin,Xmax,0)\n",
    "        self.addMass()\n",
    "\n",
    "    def allsteps(self,insteps=5000,dt=0.001):\n",
    "        nsteps=insteps\n",
    "        self.nsteps+=nsteps\n",
    "        self.regrid()\n",
    "        self.force()\n",
    "        self.firststep(dt)\n",
    "        self.regrid()\n",
    "        for t in range(nsteps):\n",
    "            if t % 500 == 0:\n",
    "                print(\"steps:\",t)\n",
    "            self.force()\n",
    "            self.step(dt)\n",
    "            self.regrid()\n",
    "            self.store()\n",
    "        return self.points()\n",
    "\n",
    "\n",
    "def animate(coords,iN=2,ymin=-10,ymax=10,xmin=-10,xmax=10,stepsize=50):\n",
    "    images = []\n",
    "    fig, ax = plt.subplots(figsize=(12,7))\n",
    "    for step in range(len(coords[0])-110):\n",
    "        if step % stepsize == 0:\n",
    "            makePlot(iN,coords[:,step:step+100],ax,fig,images,ymin=ymin,ymax=ymax,xmin=xmin,xmax=xmax)\n",
    "    return images\n",
    "\n",
    "treeStar = TreeStars(bodies,X)\n",
    "lX=treeStar.allsteps()\n",
    "fig1 = plt.figure(figsize=(10, 10))\n",
    "#fig1.subplots_adjust(wspace=0.1, hspace=0.15,left=0.1, right=0.9,bottom=0.05, top=0.9)\n",
    "plt.scatter(X[:, 0], X[:, 1])\n",
    "plt.scatter(lX[:, 0], lX[:, 1])\n",
    "#ax.set_xlim(-1.2, 1.2)\n",
    "#ax.set_ylim(-0.15, 1.15)\n",
    "plt.show()\n",
    "\n",
    "tracks=treeStar.history()\n",
    "tracks=np.swapaxes(tracks,0,1)\n",
    "images=animate(tracks,iN=30,xmin=-500,xmax=500,ymin=-500,ymax=500)\n",
    "imageio.mimsave('orbit_n_v0.gif', images, fps=10)\n",
    "Image(open('orbit_n_v0.gif','rb').read())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "566e3eff",
   "metadata": {
    "id": "566e3eff"
   },
   "source": [
    "This looks really cool, but is this doing what we expect? Lets do a quick test with a two body system to make sure everything makes sense."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e7aa0e3",
   "metadata": {
    "id": "4e7aa0e3",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "bodies = []\n",
    "mass=1 # they will all have a mass of a solar mass\n",
    "X = np.array([1,0])\n",
    "X = np.vstack((X, np.array([-1,0]) ))\n",
    "vc=circle_v(mass,1)\n",
    "V = np.array([0,-vc])\n",
    "V = np.vstack((V, np.array([0,vc]) ))\n",
    "#Xr = np.array([[4,4],[-4,-4]])\n",
    "\n",
    "bodies=[]\n",
    "pBody = body(X[0],V[0],mass)\n",
    "bodies.append(pBody)\n",
    "pBody = body(X[1],V[1],mass)\n",
    "bodies.append(pBody)\n",
    "\n",
    "treeStar = TreeStars(bodies,X)\n",
    "lX=treeStar.allsteps(insteps=1000,dt=0.001)\n",
    "fig1 = plt.figure(figsize=(10, 10))\n",
    "tracks=treeStar.history()\n",
    "tracks=np.swapaxes(tracks,0,1)\n",
    "plt.plot(tracks[0,:,0],tracks[0,:,1])\n",
    "plt.plot(tracks[1,:,0],tracks[1,:,1])\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f093c24",
   "metadata": {
    "id": "2f093c24"
   },
   "source": [
    "Now the fun part is to see how well this scales. Let's try to simulate 1000 particles and comapre it with our two optimzied scenarios, lets see how we things look."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28cb03a6",
   "metadata": {
    "id": "28cb03a6"
   },
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "np.random.seed(0)\n",
    "nparts=10000\n",
    "nsteps=2\n",
    "X = np.random.random((nparts, 2)) * 2 - 1\n",
    "V = np.random.random((nparts, 2)) * 0.1\n",
    "\n",
    "bodies = []\n",
    "for i0 in range(len(X)):\n",
    "    mass=1. # they will all have a mass of a solar mass\n",
    "    pBody = body(X[i0],V[i0],mass)\n",
    "    bodies.append(pBody)\n",
    "\n",
    "\n",
    "t0=time.perf_counter()\n",
    "\n",
    "treeStar = TreeStars(bodies,X)\n",
    "lX=treeStar.allsteps(insteps=nsteps)\n",
    "\n",
    "t1=time.perf_counter()\n",
    "print(\"N-body Tree Delta time:\",t1-t0)\n",
    "\n",
    "#Now lets setup a quick init script only for up to 4 stars\n",
    "def initN(X,V,M,iN):\n",
    "    pos=X\n",
    "    mass=M#np.ones(iN)#units of Solar Mass\n",
    "    #now v\n",
    "    v=V\n",
    "    #v=v.T\n",
    "    #transform to the com frame\n",
    "    #vcom=np.dot(mass,v)/np.sum(mass)\n",
    "    #v-=vcom\n",
    "    return pos,v,mass\n",
    "\n",
    "\n",
    "def simTest(iX,iV,iM,iN=nparts,insteps=nsteps,dt=0.001,isoften=1e-1):\n",
    "    #units of years\n",
    "    pos,vel,mass=initN(iX,iV,iM,iN)\n",
    "    allstars = stars(mass,pos,vel,iN,isoften=isoften)\n",
    "    allstars.parallelAcc()\n",
    "    allstars.firststep(dt)\n",
    "    for t in range(insteps):\n",
    "        allstars.parallelAcc()\n",
    "        allstars.step(dt)\n",
    "    x1vals=np.reshape(allstars.posh,(insteps,iN,2))\n",
    "    x1vals=np.swapaxes(x1vals,0,1)\n",
    "    return x1vals\n",
    "\n",
    "mass=np.ones(nparts)\n",
    "t2=time.perf_counter()\n",
    "simTest(X,V,mass,nparts)\n",
    "t3=time.perf_counter()\n",
    "\n",
    "print(\"N-body Parallel\",t3-t2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6779df7a",
   "metadata": {
    "id": "6779df7a"
   },
   "source": [
    "Now given all of this, lets try to do a realistic sampling and make a video of what motion might look like in the center of the galaxy. Let's sample from a gaussian distribution of stars. In turns out that the average distance between stars in the center of the galaxy is 1000 AU. So what we can do is sample a gaussian distribution with a width $\\sigma$ such that\n",
    "\n",
    "$$\n",
    "\\bar{\\Delta x_{i}} = \\frac{1}{N} \\sum_{j} |x_{i}-x_{j}|\n",
    "$$\n",
    "\n",
    "In this case, what we want is the minimimum distance, which is just given by the minimum distance if we sampled a gaussian. Since, I am too lazy to do this calculation let just do it numerically."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f3f2e1d",
   "metadata": {
    "id": "2f3f2e1d"
   },
   "outputs": [],
   "source": [
    "x = np.array([])\n",
    "y = np.array([])\n",
    "yerr = np.array([])\n",
    "for i0 in np.arange(1,10000,100):\n",
    "    n=i0\n",
    "    v0 = np.array([])\n",
    "    ntoys=100\n",
    "    for pToy in np.arange(ntoys):\n",
    "        vals=np.abs(np.random.normal(0,1,n))\n",
    "        v0  = np.append(v0,np.min(vals))\n",
    "    x = np.append(x,n)\n",
    "    y = np.append(y,v0.mean())\n",
    "    yerr = np.append(yerr,v0.std())\n",
    "\n",
    "plt.errorbar(x,y,yerr=yerr)\n",
    "plt.yscale('log')\n",
    "plt.xlabel('N')\n",
    "plt.ylabel(\"\\bar{x}_{min}\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07e317b7",
   "metadata": {
    "id": "07e317b7"
   },
   "source": [
    "What this means is tha for simulation with 1000 particles, we should sample a gaussian with $\\sigma=1000$, this will get us rougly the right spacing that we can then use to look at galactic flow over time. Let's go ahead and give this a try. Also, what we can do is set the velocity to zero, to see hwo it evolves."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af1b489d",
   "metadata": {
    "id": "af1b489d"
   },
   "outputs": [],
   "source": [
    "####Warning this box takes a few minutes to run\n",
    "nparts=1000\n",
    "nsteps=5000\n",
    "\n",
    "np.random.seed(1)\n",
    "R     = np.random.normal(0,1,nparts)*nparts*1e3\n",
    "theta = np.random.uniform(0,2*np.pi,nparts)\n",
    "X = np.vstack((R*np.cos(theta),R*np.sin(theta)))\n",
    "X = X.T\n",
    "V = np.zeros((nparts,2))\n",
    "mass=np.abs(np.random.normal(2,0.5,nparts))\n",
    "bodies = []\n",
    "for i0 in range(len(X)):\n",
    "    pBody = body(X[i0],V[i0],mass[i0])\n",
    "    bodies.append(pBody)\n",
    "\n",
    "\n",
    "t0=time.perf_counter()\n",
    "treeStar = TreeStars(bodies,X,isoften=1e2)\n",
    "treeStar.allsteps(insteps=nsteps,dt=250.0)\n",
    "t1=time.perf_counter()\n",
    "print(\"N-body Tree Delta time:\",t1-t0)\n",
    "\n",
    "t0=time.perf_counter()\n",
    "lXVals=simTest(X,V,mass,nparts,nsteps,dt=250.0,isoften=1e2)\n",
    "t1=time.perf_counter()\n",
    "print(\"Actual N-body Delta time:\",t1-t0)\n",
    "\n",
    "images=animate(lXVals,iN=nparts,xmin=-500000,xmax=500000,ymin=-500000,ymax=500000,stepsize=10)\n",
    "imageio.mimsave('orbit_n.gif', images, fps=10)\n",
    "Image(open('orbit_n.gif','rb').read())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5824c5cb",
   "metadata": {
    "id": "5824c5cb",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "tracks=treeStar.history()\n",
    "tracks=np.swapaxes(tracks,0,1)\n",
    "images=animate(tracks,iN=nparts,xmin=-1000000,xmax=1000000,ymin=-1000000,ymax=1000000,stepsize=10)\n",
    "imageio.mimsave('orbit_nt_v1.gif', images, fps=10)\n",
    "Image(open('orbit_nt_v1.gif','rb').read())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3050232a",
   "metadata": {
    "id": "3050232a"
   },
   "outputs": [],
   "source": [
    "images=animate(lXVals,iN=nparts,xmin=-1000000,xmax=1000000,ymin=-1000000,ymax=1000000,stepsize=10)\n",
    "imageio.mimsave('orbit_n_v2_v1.gif', images, fps=10)\n",
    "Image(open('orbit_n_v2_v1.gif','rb').read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "045f7f86",
   "metadata": {
    "id": "045f7f86"
   },
   "outputs": [],
   "source": [
    "images=animate(lXVals,iN=nparts,xmin=-5000000,xmax=5000000,ymin=-5000000,ymax=5000000,stepsize=10)\n",
    "imageio.mimsave('orbit_n_v3_v1.gif', images, fps=10)\n",
    "Image(open('orbit_n_v3_v1.gif','rb').read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4cdd0f8",
   "metadata": {
    "id": "e4cdd0f8"
   },
   "outputs": [],
   "source": [
    "tracks=treeStar.history()\n",
    "tracks=np.swapaxes(tracks,0,1)\n",
    "images=animate(tracks,iN=nparts,xmin=-5000000,xmax=5000000,ymin=-5000000,ymax=5000000,stepsize=10)\n",
    "imageio.mimsave('orbit_nt_v4_v1.gif', images, fps=10)\n",
    "Image(open('orbit_nt_v4_v1.gif','rb').read())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a51aa6d",
   "metadata": {
    "id": "1a51aa6d"
   },
   "source": [
    "<a name='exercises_20_4'></a>     \n",
    "\n",
    "| [Top](#section_20_0) | [Restart Section](#section_20_4) | [Next Section](#section_20_5) |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bba169f",
   "metadata": {
    "id": "2bba169f"
   },
   "source": [
    "### <span style=\"border:3px; border-style:solid; padding: 0.15em; border-color: #90409C; color: #90409C;\">Ex-20.4.1 </span>\n",
    "\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2a34e9d",
   "metadata": {
    "id": "f2a34e9d"
   },
   "source": [
    "<a name='section_20_5'></a>\n",
    "<hr style=\"height: 1px;\">\n",
    "\n",
    "## <h2 style=\"border:1px; border-style:solid; padding: 0.25em; color: #FFFFFF; background-color: #90409C\">L20.5 ML N-body Problem</h2>  \n",
    "\n",
    "| [Top](#section_20_0) | [Previous Section](#section_20_4) | [Exercises](#exercises_20_5) | [Next Section](#section_20_6) |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2280d99f",
   "metadata": {
    "id": "2280d99f"
   },
   "source": [
    "<h3>Overview</h3>\n",
    "\n",
    "Now, we are going to construct a very simple machine learning approach to stellar simulation. While, this approach will not really allow us to go into detail, we will start to grasp a concept of where machine learning is relevant in a simulation scenario.\n",
    "\n",
    "To this, we first need to pull in our usual simulation code dictating stellar evolution. We will be sure to use the leapfrog symplectic integrator. Additionally, we will use a fixed time-step.\n",
    "\n",
    "Ok, so looks ok; could be better, but thats beyond this class.\n",
    "\n",
    "Now there is a broad range of possibilities that we can consier machine learning for. Ideally, we would want to use the fact that machine learning allows us to do a function approximation, but very fast and effectively. For the use of this in simulation, we can do just that, a funcitonal approximation.\n",
    "\n",
    "Now, lets consider the situation where we have randomly sample some initial conditions and then compute a tractory for that, then from that try to predict something.\n",
    "\n",
    "To randomly sample, we are going to have same over a restricted phase space. The issue is that a full random sample of many parametes is just hard to simulate, we are trying to predict a broad range of final states, this is tricky.\n",
    "\n",
    "So for this sampling, what we will do is restrict our possible cases. We are going to restrict to a some simplified case where things are easy to solve.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edce81a4",
   "metadata": {
    "id": "edce81a4"
   },
   "outputs": [],
   "source": [
    "##So now we are going to write a script that generates 1000 random conditions and trains a neural network to predict then ext 30 time steps\n",
    "##We are going to do this for 2 body to start with\n",
    "##To keep the dimensionality down to something reasonable, we are going to do this in the COM frame\n",
    "\n",
    "def randomSamplePlanets(iN=2):\n",
    "    ###Lets simplify the coordinates\n",
    "    ###sample a radius along the x-axis\n",
    "    #radius=np.ones(iN)\n",
    "    #radius[0]=-1\n",
    "    radius=np.random.uniform(0.5,2,iN)#units of AU\n",
    "    radius[1]=-radius[0]\n",
    "    #theta=np.random.uniform(0,2.*np.pi,iN)\n",
    "    #merge positions and make sure each row is planet\n",
    "    theta=0\n",
    "    pos=np.vstack((radius*np.cos(theta),radius*np.sin(theta)))\n",
    "    pos=pos.T\n",
    "    #now mass\n",
    "    mass=np.random.uniform(0,3,iN)#units of Solar Mass\n",
    "    #mass=np.ones(iN)#units of Solar Mass\n",
    "    #now v\n",
    "    #v=circle_v(mass,np.abs(radius))*np.random.normal(0,3)\n",
    "    v=circle_v(mass,np.abs(radius))*np.abs(np.random.normal(0,1))\n",
    "    theta=np.random.uniform(0,2.*np.pi,iN)\n",
    "    v=np.vstack((v*np.cos(theta),v*np.sin(theta)))\n",
    "    v=v.T\n",
    "    #transform to the com frame\n",
    "    vcom=np.dot(mass,v)/np.sum(mass)\n",
    "    v-=vcom\n",
    "    return pos,mass,v\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77fc2776",
   "metadata": {
    "id": "77fc2776"
   },
   "source": [
    "Now what are going to do is try to predict the orbital positions of stars after running simulation for a large number of steps. To do this there are a few different things we can try to predict with the NN\n",
    "\n",
    " * The star trajectory in position space\n",
    " * The star position and momentum vector after many steps\n",
    " * The range in the position and the momentum vector\n",
    " * The velocity change over time\n",
    " * The trajectory and the velocity.\n",
    "\n",
    "Let's run our simulator and set it up to output these possibilities. Additionally, now we will run 15k simulations so that we can we deep learn the many possible trajectories."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa78fd37",
   "metadata": {
    "id": "fa78fd37"
   },
   "outputs": [],
   "source": [
    "def sim(pos,mass,v,iN=2,dt=0.001,nsteps=5,iPlot=False,iOutput=0):\n",
    "    #make the stars\n",
    "    allstars = stars(mass,pos,v,iN)\n",
    "    #simulate\n",
    "    allstars.parallelAcc()\n",
    "    allstars.totalE()\n",
    "    allstars.firststep(dt)\n",
    "    for t in range(nsteps):\n",
    "        allstars.parallelAcc()\n",
    "        allstars.totalE()\n",
    "        allstars.step(dt)\n",
    "    x1vals=np.reshape(allstars.posh,(nsteps,2*iN))\n",
    "    vvals =np.reshape(allstars.velh,(nsteps,2*iN))\n",
    "    if iPlot:\n",
    "        for i0 in np.arange(iN):\n",
    "            plt.plot(x1vals[:,2*i0],x1vals[:,2*i0+1])\n",
    "        plt.show()\n",
    "\n",
    "        plt.plot(range(nsteps),allstars.toth,label='Total')\n",
    "        plt.legend()\n",
    "        plt.xlabel('time step')\n",
    "        plt.ylabel('energy')\n",
    "        plt.show()\n",
    "    if iOutput==0: #full trajectory\n",
    "        return _,x1vals\n",
    "    if iOutput==1: #output velocity and position\n",
    "        return _,np.hstack((x1vals[-1],vvals[-1]))\n",
    "    if iOutput==2: #differences from beginning\n",
    "        dx1=x1vals[-1]-x1vals[0]\n",
    "        dv1=vvals[-1]-vvals[0]\n",
    "        return _,np.hstack((dx1,dv1))\n",
    "    if iOutput==3:\n",
    "        return _,vvals\n",
    "    if iOutput==4:\n",
    "        return x1vals,vvals\n",
    "\n",
    "\n",
    "def makeTrainDataSet(iNPoints=15000,iN=2,iOutput=0):\n",
    "    nsteps=50\n",
    "    if iOutput == 4:\n",
    "        indataset  = np.empty((0,4*nsteps), int)\n",
    "    else:\n",
    "        indataset  = np.empty((0,10), int)\n",
    "    if iOutput == 0 or iOutput == 3 or iOutput == 4:\n",
    "        outdataset = np.empty((0,4*nsteps), float)\n",
    "    else:\n",
    "        outdataset = np.empty((0,8), float)\n",
    "    for niter in range(iNPoints):\n",
    "        pos,mass,v=randomSamplePlanets(iN)\n",
    "        pIn,out=sim(pos,mass,v,nsteps=nsteps,iOutput=iOutput)\n",
    "        outdataset= np.vstack((outdataset,out.flatten()))\n",
    "        merge     = np.concatenate((v.flatten(),pos.flatten(),mass.flatten()))\n",
    "        indataset = np.vstack((indataset,merge))\n",
    "        #indataset = np.vstack((indataset,pIn.flatten()))\n",
    "    return indataset,outdataset\n",
    "\n",
    "pos,mass,v=randomSamplePlanets(2)\n",
    "sim(pos,mass,v,nsteps=5000,iPlot=True)\n",
    "trainset,targets=makeTrainDataSet()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f59c44a8",
   "metadata": {
    "id": "f59c44a8"
   },
   "source": [
    "Now our goal is to construct a deep learning model that allows us to predict the next 50 steps of our bath. Given our simulated dataset, we can go ahead and try to predict what is going on through a deep learning regression.\n",
    "\n",
    "Let's go ahead and make the model We will just make a simple ML model with a 4 layers and 20 hidden parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a2ff89f",
   "metadata": {
    "id": "6a2ff89f"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset\n",
    "from torch.autograd import Variable\n",
    "\n",
    "class MLP(nn.Module):\n",
    "    def __init__(self,n_inputs,n_outputs):\n",
    "        super(MLP, self).__init__()\n",
    "        self.layers = nn.Sequential(\n",
    "            nn.Linear(n_inputs, 20),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(20, 20),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(20, 20),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(20, 20),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(20, n_outputs),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.layers(x)\n",
    "        return x\n",
    "\n",
    "def train(x,y,net,loss_func,opt,sched,nepochs):\n",
    "    net.train(True)\n",
    "    for epoch in range(nepochs):\n",
    "        prediction = net(x)\n",
    "        opt.zero_grad()\n",
    "        loss = loss_func(prediction,y)\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "        if epoch % 500 == 0:\n",
    "            print('[%d] loss: %.4f ' % (epoch + 1, loss.item()  ))\n",
    "    sched.step()\n",
    "    return\n",
    "\n",
    "model     = MLP(trainset.shape[1],targets.shape[1])\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
    "scheduler = torch.optim.lr_scheduler.ExponentialLR(optimizer, gamma=0.1, last_epoch=-1, verbose=False)\n",
    "loss_fn   =  nn.MSELoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1175805",
   "metadata": {
    "id": "a1175805"
   },
   "source": [
    "Finally, we can go ahead and train this guy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d99af94",
   "metadata": {
    "id": "6d99af94"
   },
   "outputs": [],
   "source": [
    "tmp_tot    = torch.tensor(trainset).float()\n",
    "tmp_label  = torch.tensor(targets).float()\n",
    "train(tmp_tot,tmp_label,model,loss_fn,optimizer,scheduler,15001)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f39d718a",
   "metadata": {
    "id": "f39d718a"
   },
   "source": [
    "Now we can go ahead and run on a validation dataset and see how things are performing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fffca87",
   "metadata": {
    "id": "1fffca87"
   },
   "outputs": [],
   "source": [
    "valid_trainset,valid_targets=makeTrainDataSet(iNPoints=10)\n",
    "tmp_train  = torch.tensor(valid_trainset).float()\n",
    "tmp_target = torch.tensor(valid_targets).float()\n",
    "output_targets=model(tmp_train)\n",
    "print(output_targets.shape)\n",
    "\n",
    "#output_targets=output_targets.reshape(output_targets.shape[0],5,4).detach().numpy()\n",
    "#valid_targets =tmp_target.reshape(tmp_target.shape[0],5,4).detach().numpy()\n",
    "output_targets=output_targets.reshape(output_targets.shape[0],50,4).detach().numpy()\n",
    "valid_targets =tmp_target.reshape(tmp_target.shape[0],50,4).detach().numpy()\n",
    "#output_targets=output_targets.reshape(output_targets.shape[0],1,8).detach().numpy()\n",
    "#valid_targets =tmp_target.reshape(tmp_target.shape[0],1,8).detach().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e25d7f51",
   "metadata": {
    "id": "e25d7f51",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for batch in np.arange(10):\n",
    "    for i0 in np.arange(2):\n",
    "        plt.plot(output_targets[batch,:,0+2*i0],output_targets[batch,:,1+2*i0], color='red',label='pred')\n",
    "        plt.plot(valid_targets [batch,:,0+2*i0],valid_targets [batch,:,1+2*i0], color='blue',alpha=0.5,label='true')\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37012a46",
   "metadata": {
    "id": "37012a46"
   },
   "source": [
    "Ok, its nice that we can predict the paths quite well, and I find it pertty remarkable to be honest. However, to really make a power prediction, what we would like to do is predict the position and velocity after 50 steps. This way we can reduce the overall step size, and let the neural network do the \"inpainting\" of what is going on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0244298c",
   "metadata": {
    "id": "0244298c"
   },
   "outputs": [],
   "source": [
    "trainset,targets=makeTrainDataSet(iOutput=2)\n",
    "model     = MLP(trainset.shape[1],targets.shape[1])\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
    "scheduler = torch.optim.lr_scheduler.ExponentialLR(optimizer, gamma=0.1, last_epoch=-1, verbose=False)\n",
    "loss_fn   =  nn.MSELoss()\n",
    "tmp_tot    = torch.tensor(trainset).float()\n",
    "tmp_label  = torch.tensor(targets).float()\n",
    "train(tmp_tot,tmp_label,model,loss_fn,optimizer,scheduler,15001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a0af098",
   "metadata": {
    "id": "3a0af098",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "valid_trainset,valid_targets=makeTrainDataSet(iNPoints=10,iOutput=2)\n",
    "tmp_train  = torch.tensor(valid_trainset).float()\n",
    "tmp_target = torch.tensor(valid_targets).float()\n",
    "output_targets=model(tmp_train)\n",
    "output_targets=output_targets.reshape(output_targets.shape[0],1,8).detach().numpy()\n",
    "valid_targets =tmp_target.reshape(tmp_target.shape[0],1,8).detach().numpy()\n",
    "#print(valid_targets.shape)\n",
    "for batch in np.arange(10):\n",
    "    for i0 in np.arange(2):\n",
    "        plt.arrow(output_targets[batch,0,0+2*i0],output_targets[batch,0,1+2*i0],output_targets[batch,0,4+2*i0],output_targets[batch,0,5+2*i0],width=.05, edgecolor='red',facecolor='red')\n",
    "        plt.arrow(valid_targets [batch,0,0+2*i0],valid_targets [batch,0,1+2*i0],valid_targets [batch,0,4+2*i0],valid_targets [batch,0,5+2*i0],width=.05, edgecolor='blue',facecolor='blue',alpha=0.5)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8526cd47",
   "metadata": {
    "id": "8526cd47"
   },
   "source": [
    "Now, what we can do is try to improve our simulation by requiring that our system conserves energy. The simplest way to do that is to add energy conservation as a constraint in the loss function. Since we are computing the the change in the relative position of the planets, what this means is that the derivative of the total energy is zero. We can write this as:\n",
    "\n",
    "$$\n",
    "\\mathcal{H} = \\frac{1}{2} m_{1} v_{1}^{2} + \\frac{1}{2} m_{2} v_{2}^2 + \\frac{Gm_{1}m_{2}}{|\\vec{r}_{1}-\\vec{r}_{2}|}\\\\\n",
    "\\frac{d\\mathcal{H}}{dt} = 0 \\\\\n",
    "\\frac{d\\mathcal{H}}{dt}  = mv_{1} \\frac{dv_{1}}{dt} + mv_{2} \\frac{dv_{2}}{dt} + \\frac{Gm_{1}m_{2}}{|\\vec{r}_{1}-\\vec{r}_{2}|^{2}}\\left(\\frac{dr_{1}}{dt} + \\frac{dr_2}{dt}\\right) = 0\n",
    "$$\n",
    "\n",
    "Additionally, we can could also impose angular momentum conservation\n",
    "\n",
    "$$\n",
    "L_{\\rm tot} = m_{1} v_{1} r_{1} +  m_{2} v_{2} r_{2}\\\\\n",
    "\\frac{d L_{\\rm tot}}{dt} = m_{1}\\left(\\frac{dv_{1}}{dt} r_{1} + v_{1}\\frac{dr_{1}}{dt}\\right) + m_{2}\\left(\\frac{dv_{2}}{dt} r_{2} + v_{2}\\frac{dr_{2}}{dt}\\right)\n",
    "$$\n",
    "\n",
    "Mostly in the inerest of being lazy, lets add angular momentum conservation conservation as a constraint."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d97bb4ee",
   "metadata": {
    "id": "d97bb4ee"
   },
   "outputs": [],
   "source": [
    "def energy(iVec):\n",
    "    dr = torch.pow(torch.norm(iVec[:,4:6]-iVec[:,6:8],dim=1),-0.5)\n",
    "    v2 = torch.sum(iVec[:,0:4]**2,dim=1)\n",
    "    return dr+v2\n",
    "\n",
    "def newEloss(prediction,y_data,iloss=loss_fn,lam=1e-1):\n",
    "    #rint(prediction.shape,y_data.shape)\n",
    "    mse=iloss(prediction,y_data)\n",
    "    en1=energy(y_data)\n",
    "    en0=energy(prediction)\n",
    "    #grad=torch.autograd.grad(en0, inputs, torch.ones_like(en0), create_graph=True)[0]\n",
    "    return mse + lam*torch.mean((en1-en0)**2)\n",
    "\n",
    "def ang(iInput,iPred):\n",
    "    im1 = iInput[:,8]\n",
    "    im2 = iInput[:,9]\n",
    "    iv1 = iInput[:,0:2]\n",
    "    iv2 = iInput[:,2:4]\n",
    "    ir1 = iInput[:,4:6]\n",
    "    ir2 = iInput[:,6:8]\n",
    "    dr1 = iPred[:,0:2]\n",
    "    dr2 = iPred[:,2:4]\n",
    "    dv1 = iPred[:,4:6]\n",
    "    dv2 = iPred[:,6:8]\n",
    "    return im1*(torch.sum(dv1*ir1,dim=1)+torch.sum(iv1*dr1,dim=1))+im2*(torch.sum(dv2*ir2,dim=1)+torch.sum(iv2*dr2,dim=1))\n",
    "\n",
    "def newAloss(prediction,y_data,iInput,iloss=loss_fn,lam=1e-1):\n",
    "    dL=ang(iInput,prediction)\n",
    "    mse=iloss(prediction,y_data)\n",
    "    return mse + lam*torch.mean(dL**2)\n",
    "\n",
    "valid_trainset,valid_targets=makeTrainDataSet(iNPoints=10,iOutput=1)\n",
    "tmp_train  = torch.tensor(valid_trainset).float()\n",
    "tmp_target = torch.tensor(valid_targets).float()\n",
    "output_targets=model(tmp_train)\n",
    "\n",
    "def trainA(x,y,net,loss_func,opt,sched,nepochs):\n",
    "    net.train(True)\n",
    "    for epoch in range(nepochs):\n",
    "        prediction = net(x)\n",
    "        opt.zero_grad()\n",
    "        loss = loss_func(prediction,y,x)\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "        if epoch % 500 == 0:\n",
    "            print('[%d] loss: %.4f ' % (epoch + 1, loss.item()  ))\n",
    "    sched.step()\n",
    "    return\n",
    "\n",
    "losstest = newAloss(output_targets,tmp_target,tmp_train,loss_fn)\n",
    "print(losstest,losstest.backward())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5ccf472",
   "metadata": {
    "id": "e5ccf472"
   },
   "outputs": [],
   "source": [
    "trainA(tmp_tot,tmp_label,model,newAloss,optimizer,scheduler,5001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7da09cfe",
   "metadata": {
    "id": "7da09cfe",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "valid_trainset,valid_targets=makeTrainDataSet(iNPoints=10,iOutput=2)\n",
    "tmp_train  = torch.tensor(valid_trainset).float()\n",
    "tmp_target = torch.tensor(valid_targets).float()\n",
    "output_targets=model(tmp_train)\n",
    "output_targets=output_targets.reshape(output_targets.shape[0],1,8).detach().numpy()\n",
    "valid_targets =tmp_target.reshape(tmp_target.shape[0],1,8).detach().numpy()\n",
    "#print(valid_targets.shape)\n",
    "for batch in np.arange(10):\n",
    "    for i0 in np.arange(2):\n",
    "        plt.arrow(output_targets[batch,0,0+2*i0],output_targets[batch,0,1+2*i0],output_targets[batch,0,4+2*i0],output_targets[batch,0,5+2*i0],width=.05, edgecolor='red',facecolor='red')\n",
    "        plt.arrow(valid_targets [batch,0,0+2*i0],valid_targets [batch,0,1+2*i0],valid_targets [batch,0,4+2*i0],valid_targets [batch,0,5+2*i0],width=.05, edgecolor='blue',facecolor='blue',alpha=0.5)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e99a56e",
   "metadata": {
    "id": "6e99a56e",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def prepInputs(iPos,iV,iM):\n",
    "    dvec=iPos[0]-iPos[1]\n",
    "    theta = -1.*np.arctan2(dvec[1],dvec[0])\n",
    "    rot = np.array([[np.cos(theta), -np.sin(theta)], [np.sin(theta), np.cos(theta)]])\n",
    "    #rotate\n",
    "    opos=np.reshape(np.zeros(4),(2,2))\n",
    "    opos[0] = np.dot(rot, iPos[0])\n",
    "    opos[1] = np.dot(rot, iPos[1])\n",
    "    ovel=np.reshape(np.zeros(4),(2,2))\n",
    "    ovel[0] = np.dot(rot, iV[0])\n",
    "    ovel[1] = np.dot(rot, iV[1])\n",
    "    #set y-coordinate to exactly 0\n",
    "    #opos[0,1]=0\n",
    "    #opos[1,1]=0\n",
    "    merge=np.concatenate((ovel.flatten(),opos.flatten(),iM.flatten()))\n",
    "    lInput=torch.tensor(merge).float()\n",
    "    return lInput\n",
    "\n",
    "\n",
    "#def prepOutput(iPos,iInf):\n",
    "#    theta = -1.*np.arctan2(iPos[:,1],iPos[:,0])\n",
    "#    rot = np.array([[np.cos(theta), -np.sin(theta)], [np.sin(theta), np.cos(theta)]])\n",
    "#    #rotate\n",
    "#    lPos   = iInf\n",
    "#    opos=np.reshape(np.zeros(4),(2,2))\n",
    "#    opos[0] = np.dot(rot, lPos[0])\n",
    "#    opos[1] = np.dot(rot, lPos[1])\n",
    "#    return opos\n",
    "\n",
    "#Now lets run a simulator for this\n",
    "def mlSim(pos,mass,v,iN=2,dt=0.001,nsteps=10,iPlot=False,iOutput=1):\n",
    "    posh = np.array([])\n",
    "    velh = np.array([])\n",
    "    lPos = pos\n",
    "    lV   = v\n",
    "    lInput = prepInputs(pos,v,mass)\n",
    "    for i0 in range(nsteps):\n",
    "        output = model(lInput)\n",
    "        lPos   += output[0:4].reshape(2,2).detach().numpy()\n",
    "        lV     += output[4:8].reshape(2,2).detach().numpy()\n",
    "        posh   = np.append(posh,lPos)\n",
    "        velh   = np.append(velh,lV)\n",
    "        lInput = prepInputs(lPos,lV,mass)\n",
    "    if iPlot:\n",
    "        posh=np.reshape(posh,(nsteps,2*iN))\n",
    "        for i0 in np.arange(iN):\n",
    "            plt.plot(posh[:,2*i0],posh[:,2*i0+1])\n",
    "        plt.show()\n",
    "\n",
    "np.random.seed(10)\n",
    "pos,mass,v=randomSamplePlanets(2)\n",
    "import time\n",
    "start_time = time.time()\n",
    "sim(pos,mass,v,nsteps=500,iPlot=True)\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))\n",
    "start_time = time.time()\n",
    "mlSim(pos,mass,v,iPlot=True,nsteps=10)\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d476944",
   "metadata": {
    "id": "4d476944"
   },
   "source": [
    "<a name='exercises_20_5'></a>     \n",
    "\n",
    "| [Top](#section_20_0) | [Restart Section](#section_20_5) | [Next Section](#section_20_6) |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7766de09",
   "metadata": {
    "id": "7766de09"
   },
   "source": [
    "### <span style=\"border:3px; border-style:solid; padding: 0.15em; border-color: #90409C; color: #90409C;\">Ex-20.5.1 </span>\n",
    "\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b49f136d",
   "metadata": {
    "id": "b49f136d"
   },
   "source": [
    "<a name='section_20_6'></a>\n",
    "<hr style=\"height: 1px;\">\n",
    "\n",
    "## <h2 style=\"border:1px; border-style:solid; padding: 0.25em; color: #FFFFFF; background-color: #90409C\">L20.6 1D Hydrodynamical Solutions</h2>  \n",
    "\n",
    "| [Top](#section_20_0) | [Previous Section](#section_20_5) | [Exercises](#exercises_20_6) | [Next Section](#section_20_7) |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c087761",
   "metadata": {
    "id": "0c087761"
   },
   "source": [
    "<h3>Overview</h3>\n",
    "\n",
    "Note: from here https://zingale.github.io/computational_astrophysics/ODEs/ODEs-conservation.html\n",
    "\n",
    "Now that we have developed the concept of how to solve 1D differential equations. Moreover, we have even applied this to the notion of planetary interations. We would like to do consider a regular grid of objects, kind of like what we did with the tree above. However, now we are going to keep our objects fixed, and use the fact that they are fixed to try to solve a partial differential equation.\n",
    "\n",
    "First, lets imagine we have a box filled with water, and we discritzie this box to have various levels of water."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e39b86e7",
   "metadata": {
    "id": "e39b86e7"
   },
   "outputs": [],
   "source": [
    "import scipy.stats as stats\n",
    "\n",
    "ngrid=10\n",
    "gridx=np.arange(-10,10,20/ngrid)\n",
    "gridy=stats.norm.pdf(gridx,0,3)\n",
    "plt.plot(gridx, gridy, drawstyle='steps-mid', label='steps-mid')\n",
    "plt.xlabel('x-position')\n",
    "plt.ylabel('height')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76171d05",
   "metadata": {
    "id": "76171d05"
   },
   "source": [
    "Now imagine for some crazy reason, that this a mountain of water describd by a discretized probability distribution function given by above, and this mountain is moving with some velocity $v$. The equation of motion for this moutain can be written as\n",
    "\n",
    "$$\n",
    "\\frac{\\partial p}{\\partial x} - v \\frac{\\partial p}{\\partial t} = 0\n",
    "$$\n",
    "\n",
    "This is often called the 1D Euler equation or just the Burger's equation. The solution to this is the pdf $p(x,t)$ moves with a velocity of $v$ in this case its a normal distribution sliding to the right.\n",
    "\n",
    "$$\n",
    "p(x,t) = \\mathcal{N} (\\mu=x-vt,\\sigma)\n",
    "$$\n",
    "\n",
    "We can also solve this numerically by noting that we can translate each element of our grid into motion characterized by its neighbour. The way we do this is tha for each bin ($b^{t+1}_{i}$) at time $t+1$ we modify it during time by its neighbours and its previous bin by noting the motion of the system will cause the current bin to lose a fraction of its elements with the fraction given by $C=\\frac{\\Delta x_{t+1-t}}{\\Delta x_{\\rm bin}}$ the amount of motion in a step over the bin size, which we can writing noting the velocity $v$ as\n",
    "\n",
    "$$\n",
    "b^{t+1}_{i} = b^{t}_{i} - \\frac{v\\Delta t}{\\Delta x} b^{t}_{i} + \\frac{v\\Delta t}{\\Delta x} b^{t}_{i-1}\n",
    "$$\n",
    "\n",
    "where the last term is the addition of stuff coming from the bin right next to it. As a side note, the term $C=\\frac{\\Delta x_{t+1-t}}{\\Delta x_{\\rm bin}}$ is called the Courant-Fredrichs-Lewy condition.\n",
    "\n",
    "Ok now lets evolve it, to make things easier, we are going to do this with video game geomtery, or if you jump on the right you will end up on the left. For this, we are going to use the roll command, lets quickly see how it works.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4492e908",
   "metadata": {
    "id": "4492e908"
   },
   "outputs": [],
   "source": [
    "array=np.arange(1,10,1)\n",
    "print(array)\n",
    "print(np.roll(array,1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "effbc3d7",
   "metadata": {
    "id": "effbc3d7"
   },
   "source": [
    "Our strategy will then be to shift our distribution by one unit, and then average the current distribution with the shifted distribution by the velocity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f1a593f",
   "metadata": {
    "id": "1f1a593f"
   },
   "outputs": [],
   "source": [
    "def evolvepdf(xvals,pdf,v,dt):\n",
    "    C = v*dt/(xvals[1]-xvals[0])\n",
    "    pdf = pdf*(1-C) + np.roll(pdf,-1)*C\n",
    "    #pdf = pdf + np.roll(pdf,-1)*C*0.5 - np.roll(pdf,1)*C*0.5\n",
    "    return pdf\n",
    "\n",
    "#ok lets step it once and check\n",
    "gridx=np.arange(-10,10,20/ngrid)\n",
    "gridy=stats.norm.pdf(gridx,0,3)\n",
    "plt.plot(gridx,gridy,drawstyle='steps-mid')\n",
    "newgridy=gridy\n",
    "for i0 in range(1):\n",
    "    newgridy=evolvepdf(gridx,newgridy,1,1)\n",
    "plt.plot(gridx,newgridy,drawstyle='steps-mid')\n",
    "plt.show()\n",
    "\n",
    "#now lets step it a few times and make a video\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc750c1f",
   "metadata": {
    "id": "dc750c1f"
   },
   "source": [
    "Now the interesting thing is to test this guy over time. What if we evolve a top hat distribution moving to the right 100 steps or even more? Ideally, our top-hat should be preserved, but this shifting is definitely not perfect. Lets go ahead and evolve our top hat 2000 steps over a distance of 20. This should just reproduce the original top hat distribution at the same position. What do you think will happen?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f4c0768",
   "metadata": {
    "id": "3f4c0768"
   },
   "outputs": [],
   "source": [
    "#now lets evolve a hat with 100 steps\n",
    "ngrid=100\n",
    "gridx=np.arange(-10,10,20/ngrid)\n",
    "gridy=np.ones(gridx.shape)\n",
    "gridy[0:20]=0\n",
    "gridy[80:100]=0\n",
    "#gridy=np.sin(gridx)**2\n",
    "gridy*=1./np.sum(gridy) #normalize it\n",
    "\n",
    "def evolve(igridx,igridy,idt,iv):\n",
    "    plt.plot(igridx,igridy,drawstyle='steps-mid')\n",
    "    niter=2000\n",
    "    for i in range(niter):\n",
    "        igridy=evolvepdf(igridx,igridy,iv,idt)\n",
    "    plt.plot(igridx,igridy,drawstyle='steps-mid')\n",
    "    return igridy\n",
    "\n",
    "outy=evolve(gridx,gridy,0.1,0.1) #if we do 1000 iterations of 0.1 that is a distance of 100 or 10 times around\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4bd4922",
   "metadata": {
    "id": "d4bd4922"
   },
   "source": [
    "You can see that the top hat is starting to deflate over time. This deflation is a result of the inaccuracy of our sysem to evolve the fluid flow. It eventually starts to fall apart, this is the issue with numerical simulations that we have seen time and time again. Numerics are only so good without some physics intution.\n",
    "\n",
    "\n",
    "A quick way to understand why the convergence breaks down, we can imagine fourier transforming our tophat distribution. If we consider a single fourier mode our amplitude formula. Let's take our amplitude formula\n",
    "\n",
    "$$\n",
    "b^{t+1}_{i} = b^{t}_{i} - \\frac{v\\Delta t}{\\Delta x} b^{t}_{i} + \\frac{v\\Delta t}{\\Delta x} b^{t}_{i-1} \\\\\n",
    "b^{t+1}_{i} = b^{t}_{i} - \\frac{C}{2} \\left( b^{t}_{i} -  b^{t}_{i-1} \\right)\n",
    "$$\n",
    "\n",
    "Now isolating a single Fouier mode we have with $I=\\sqrt{-1}$ to avoid complications in toation\n",
    "\n",
    "$$\n",
    "\\tilde{b}^{t+1}_{i}e^{Ii\\theta} = \\tilde{b}^{t}e^{Ii\\theta} - \\frac{C}{2} \\left(  \\tilde{b}^{t}e^{I(i+1)\\theta}  -  \\tilde{b}^{t} e^{I(i-1)\\theta}  \\right) \\\\\n",
    "\\tilde{b}^{t+1}_{i} = \\tilde{b}^{t}\\left(1 - \\frac{C}{2} \\left(  e^{I\\theta}  -   e^{I\\theta}  \\right)\\right) \\\\\n",
    "\\tilde{b}^{t+1}_{i} = \\tilde{b}^{t}\\left(1 - C I\\sin\\theta\\right)\\\\\n",
    "$$\n",
    "\n",
    "or in other words the change in the amplitude of this mode is given by\n",
    "\n",
    "$$\n",
    "|\\frac{\\tilde{b}^{t+1}}{\\tilde{b}^{t}}|^{2} = 1+C^2\\sin^{2}\\theta\n",
    "$$\n",
    "\n",
    "This means that as long as we continue to iterate over and over again, we will always smear things out (adding mroe and more fouier modes). Eventually we will just end up with something flat.\n",
    "\n",
    "Lets now try construct something that is a little more robust. Lets consider our distribution is an approximation of a a continuous distribution $f(x)$. We can thus make a computation of the derivative of the pdf by noting that in a histogram the best esitmate of the pdf is from the center of the bin. This gives us\n",
    "\n",
    "$$\n",
    "\\frac{df}{dx} = \\frac{f(x+\\frac{\\Delta x}{2})-f(x-\\frac{\\Delta x}{2})}{\\Delta x}\n",
    "$$\n",
    "\n",
    "As a result, we can then write\n",
    "\n",
    "$$\n",
    "f(x,t+\\Delta t) = f(x) + \\frac{\\Delta x}{\\Delta t} \\Delta t  \\frac{df}{dx}\n",
    "$$\n",
    "\n",
    "and a better approximation becomes\n",
    "\n",
    "$$\n",
    "f(x,t+\\Delta t) = f(x) + \\frac{\\Delta x}{\\Delta t} \\Delta t  \\frac{df}{dx}(t+\\frac{\\Delta t}{2})\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e144bd6d",
   "metadata": {
    "id": "e144bd6d"
   },
   "outputs": [],
   "source": [
    "def dpdfdx(xvals,pdf):\n",
    "    dx=(xvals[1]-xvals[0])\n",
    "    dpdfdx     = 0.5*(np.roll(pdf,2)-pdf)#df/dx (dx=bin)\n",
    "    pdfshift = pdf    + 0.5*dpdfdx#f(x+dx/2) => shift by 1/2 a bin\n",
    "    #nwo the diervaitve\n",
    "    return (np.roll(pdfshift,-1)-pdfshift)/dx #df(x+dx/2)/dx\n",
    "\n",
    "def evolvepdf(xvals,pdf,v,dt):\n",
    "    C = v*dt\n",
    "    dpdf     = dpdfdx(xvals,pdf)\n",
    "    pdf2     = pdf + 0.5*C*dpdf #f(x,t+dt/2)\n",
    "    dpdf     = dpdfdx(xvals,pdf2)  #dff(x,t+dt/2)/dx\n",
    "    pdf      += C*dpdf #shift it\n",
    "    return pdf\n",
    "\n",
    "\n",
    "def evolve(igridx,igridy,idt,iv):\n",
    "    plt.plot(igridx,igridy,drawstyle='steps-mid')\n",
    "    niter=2000\n",
    "    for i in range(niter):\n",
    "        igridy=evolvepdf(igridx,igridy,iv,idt)\n",
    "    plt.plot(igridx,igridy,drawstyle='steps-mid')\n",
    "    return igridy\n",
    "\n",
    "#now lets evolve a hat with 100 steps\n",
    "ngrid=100\n",
    "gridx=np.arange(-10,10,20/ngrid)\n",
    "gridy=np.ones(gridx.shape)\n",
    "gridy[0:20]=0\n",
    "gridy[80:100]=0\n",
    "#gridy=np.sin(gridx)**2\n",
    "outy=evolve(gridx,gridy,0.1,0.05)\n",
    "print(np.sum(gridy),np.sum(outy))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03baedde",
   "metadata": {
    "id": "03baedde"
   },
   "source": [
    "Now, we can do even better than this by improving our approximations This is very much like what we did with the leapfrog method and the Runge-kutta methods. Here what we are doing is improving our estimation of the derivative. We can do this by\n",
    "\n",
    "$$\n",
    "\\frac{df}{dx} = \\min\\left(\\frac{f(x)-f(x-\\Delta x)}{\\Delta x} , \\frac{f(x+\\Delta x)-f(x)}{\\Delta x}\\right) \\\\\n",
    "$$\n",
    "\n",
    "Now noting that derivate if there is a minima in a bin ie\n",
    "\n",
    "\n",
    "$$\n",
    "\\frac{f(x)-f(x-\\Delta x)}{\\Delta x} \\times \\frac{f(x+\\Delta x)-f(x)}{\\Delta x} < 0\n",
    "$$\n",
    "\n",
    "we take a slope of zero. From there we can then go ahead and compute\n",
    "\n",
    "$$\n",
    "\\frac{df}{dx}(x+\\frac{\\Delta x}{2})\n",
    "$$\n",
    "\n",
    "using the above distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ba14309",
   "metadata": {
    "id": "0ba14309"
   },
   "outputs": [],
   "source": [
    "def dpdfdx(xvals,pdf):\n",
    "    dx=(xvals[1]-xvals[0])\n",
    "    dpdfu     = (np.roll(pdf,1)-pdf)#b_[i+1]-b_{i}\n",
    "    dpdfd     = (pdf-np.roll(pdf,-1))#b_[i]-b_{i-1}\n",
    "    dpdfmin   = np.where(np.fabs(dpdfd) < np.fabs(dpdfu), dpdfd, dpdfu) #min diff\n",
    "    dpdfmin   = np.where(dpdfd*dpdfu > 0, dpdfmin, 0) #min diff\n",
    "    pdfshift  = pdf    + 0.5*dpdfmin#shift by 1/2 a bin\n",
    "    return (np.roll(pdfshift,-1)-pdfshift)/dx #This ensures integral is conserved\n",
    "\n",
    "def evolvepdf(xvals,pdf,v,dt):\n",
    "    C = v*dt\n",
    "    dpdf     = dpdfdx(xvals,pdf)\n",
    "    pdf2     = pdf + 0.5*C*dpdf #shift it half\n",
    "    dpdf     = dpdfdx(xvals,pdf2)  #dff(x,t+dt/2)/dx\n",
    "    pdf      += C*dpdf #shift it\n",
    "    return pdf\n",
    "\n",
    "def evolve(igridx,igridy,idt,iv):\n",
    "    plt.plot(igridx,igridy,drawstyle='steps-mid')\n",
    "    niter=2000\n",
    "    for i in range(niter):\n",
    "        igridy=evolvepdf(igridx,igridy,iv,idt)\n",
    "    plt.plot(igridx,igridy,drawstyle='steps-mid')\n",
    "    return igridy\n",
    "\n",
    "#now lets evolve a hat with 100 steps\n",
    "ngrid=100\n",
    "gridx=np.arange(-10,10,20/ngrid)\n",
    "gridy=np.ones(gridx.shape)\n",
    "gridy[0:20]=0\n",
    "gridy[80:100]=0\n",
    "#gridy=np.sin(gridx)**2\n",
    "outy=evolve(gridx,gridy,0.1,0.05)\n",
    "print(np.sum(gridy),np.sum(outy))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fe7ab4f",
   "metadata": {
    "id": "9fe7ab4f"
   },
   "source": [
    "ok now lets actually do the Inviscid Berger's equation  ( https://en.wikipedia.org/wiki/Burgers%27_equation)\n",
    "\n",
    "$$\n",
    "\\frac{\\partial v}{\\partial t} - v \\frac{\\partial v}{\\partial x} = 0 \\\\\n",
    "\\frac{\\partial v}{\\partial t} - \\frac{1}{2} \\frac{\\partial v^{2}}{\\partial x}=0\n",
    "$$\n",
    "\n",
    "This shows the diffusion flow a system. The difference with above is that the $v$ is now the funciton we want to solve.\n",
    "\n",
    "Instead of a pdf, we are now solving for $v(x,t)$.\n",
    "\n",
    "The way we are going to do this is we now need to compute\n",
    "\n",
    "$$\n",
    "\\frac{\\partial u}{\\partial x}  = \\min\\left(\\frac{u(x)-u(x-\\Delta x)}{\\Delta x} , \\frac{u(x+\\Delta x)-u(x)}{\\Delta x}\\right)\n",
    "$$\n",
    "\n",
    "Then what we do is approximate is the velocity going out of the bin, and the velocity of the fluid going into the bin\n",
    "\n",
    "$$\n",
    "u_{l} = u(x-\\frac{\\Delta x}{2})\\\\\n",
    "u_{r} = u(x+\\frac{\\Delta x}{2})\n",
    "$$\n",
    "\n",
    "If we have $u_{r} > u_{l}\\rightarrow u_{r} + u_{l} > 0$  then we have that fluid is leaving the bin. However if its less than 0, then we have that fluid is piling up.  At this stage\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8b67d5d",
   "metadata": {
    "id": "b8b67d5d",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def dpdfdx(xvals,pdf,shock=False):\n",
    "    dx=(xvals[1]-xvals[0])\n",
    "    #compute\n",
    "    dpdfr     = (np.roll(pdf,-1)-pdf)#b_[i+1]-b_{i}\n",
    "    dpdfl     = (pdf-np.roll(pdf,1))#b_[i]-b_{i-1}\n",
    "    dpdfmin   = np.where(np.fabs(dpdfl) < np.fabs(dpdfr), dpdfl, dpdfr) #min diff\n",
    "    dpdfmin   = np.where(dpdfr*dpdfl > 0, dpdfmin, 0) #if sign change take zero\n",
    "    #Now compute the difference\n",
    "    pdfshiftl = pdf    - 0.5*dpdfmin#f(x-dX/2)\n",
    "    pdfshiftr = np.roll(pdf,1)    + 0.5*np.roll(dpdfmin,1)#f(x+dx/2) => note shift to match the two\n",
    "\n",
    "    #shock wave\n",
    "    S = 0.5 * (pdfshiftr + pdfshiftl)#aggregate velocity\n",
    "    ushock = np.where(S   > 0.0, pdfshiftr, pdfshiftl) #computate aggregate velocity take ther right direction given\n",
    "    ushock = np.where(S  == 0.0, 0.0, ushock) #Check its not zero\n",
    "\n",
    "    #normal wave\n",
    "    urare  = np.where(pdfshiftl <= 0.0, pdfshiftl, 0.0) #if right vel < 0 keep it\n",
    "    urare  = np.where(pdfshiftr >= 0.0, pdfshiftr, urare) #if left vel > 0 keep that over previous\n",
    "    if shock:\n",
    "        us     = np.where(pdfshiftr > pdfshiftl, ushock, urare) #if right is greater than left (compression) do shock\n",
    "    else:\n",
    "        us     = urare\n",
    "    #now shift the bin\n",
    "    return (np.roll(us,0)**2 - np.roll(us,-1)**2)/dx\n",
    "\n",
    "def evolvepdf(xvals,pdf,dtstep,shock=False):\n",
    "    eps=0.1\n",
    "    dx=(xvals[1]-xvals[0])\n",
    "    dt = dtstep*dx/(np.max(np.abs(pdf))+eps)\n",
    "    C = 0.5*dt\n",
    "    dpdf     =  dpdfdx(xvals,pdf,shock)\n",
    "    pdf2     =  pdf + 0.5*C*dpdf #shift it half\n",
    "    dpdf     =  dpdfdx(xvals,pdf2,shock) #compute exptected shift\n",
    "    pdf      += C*dpdf #shift it\n",
    "    return pdf,dt\n",
    "\n",
    "\n",
    "def makePlot(ixvals,iyvals,ax,fig,images,ymin=-1,ymax=1,xmin=0,xmax=1.0):\n",
    "    # plot and show learning process\n",
    "    plt.cla()\n",
    "    ax.set_xlabel('x', fontsize=24)\n",
    "    ax.set_ylabel('v(x)', fontsize=24)\n",
    "    ax.set_ylim(ymin,ymax)\n",
    "    ax.set_xlim(xmin,xmax)\n",
    "    ax.plot(ixvals,iyvals,drawstyle='steps-mid')\n",
    "    fig.canvas.draw()       # draw the canvas, cache the renderer\n",
    "    image = np.frombuffer(fig.canvas.tostring_rgb(), dtype='uint8')\n",
    "    image  = image.reshape(fig.canvas.get_width_height()[::-1] + (3,))\n",
    "    images.append(image)\n",
    "\n",
    "\n",
    "def evolve(images,igridx,igridy,idt,shock=False):\n",
    "    plt.plot(igridx,igridy,drawstyle='steps-mid')\n",
    "    niter=250\n",
    "    time=0\n",
    "    fig, ax = plt.subplots(figsize=(12,7))\n",
    "    for i in range(niter):\n",
    "        igridy,pdt=evolvepdf(igridx,igridy,idt,shock=shock)\n",
    "        time+=pdt\n",
    "        makePlot(igridx,igridy,ax,fig,images)\n",
    "    plt.plot(igridx,igridy,drawstyle='steps-mid')\n",
    "    return igridy\n",
    "\n",
    "#now lets evolve a hat with 100 steps\n",
    "ngrid=100\n",
    "gridx=np.arange(0,1,1/ngrid)\n",
    "gridybase=np.zeros(gridx.shape)\n",
    "def sine(igridx,igridy):\n",
    "    index = np.logical_and(igridx >= 0.333,igridx <= 0.666)\n",
    "    igridy[index] += gridx[index]*(1.5*np.sin(2.0*np.pi*(igridx[index]-0.333)/0.333))\n",
    "    return igridy\n",
    "gridy=sine(gridx,gridybase)\n",
    "\n",
    "gridy=stats.norm.pdf(gridx,0.5,0.2)-1\n",
    "#gridy[0:10]=0\n",
    "#gridy[90:100]=0\n",
    "\n",
    "#gridy=np.ones(gridx.shape)*0.8\n",
    "#gridy[0:10]=0\n",
    "#gridy[90:100]=0\n",
    "\n",
    "images=[]\n",
    "outy=evolve(images,gridx,gridy,0.5,shock=True)\n",
    "\n",
    "from IPython.display import Image\n",
    "imageio.mimsave('data/L15/berger.gif', images, fps=10)\n",
    "Image(open('data/L15/berger.gif','rb').read())\n",
    "\n",
    "\n",
    "#gridybase=np.zeros(gridx.shape)\n",
    "#gridy=sine(gridx,gridybase)\n",
    "#outy=evolve(gridx,gridy,0.5,shock=False)\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a0a1bbd",
   "metadata": {
    "id": "1a0a1bbd"
   },
   "source": [
    "<a name='exercises_20_6'></a>     \n",
    "\n",
    "| [Top](#section_20_0) | [Restart Section](#section_20_6) | [Next Section](#section_20_7) |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad32820d",
   "metadata": {
    "id": "ad32820d"
   },
   "source": [
    "### <span style=\"border:3px; border-style:solid; padding: 0.15em; border-color: #90409C; color: #90409C;\">Ex-20.6.1 </span>\n",
    "\n",
    "Repeat the top hat evolution with 1/10th the time step, how much does this lead to the diulation?\n",
    "\n",
    "\n",
    "(Question for later, how does the time step and velocity impact our precisiion? )\n",
    "Q: What happens for a sine wave?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "004edde4",
   "metadata": {
    "id": "004edde4"
   },
   "source": [
    "<div style=\"border:1.5px; border-style:solid; padding: 0.5em; border-color: #90409C; color: #90409C;\">\n",
    "\n",
    "**SOLUTION:**\n",
    "\n",
    "<pre>\n",
    "\n",
    "</pre>\n",
    "        \n",
    "**EXPLANATION:**\n",
    "\n",
    "    \n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da25731b",
   "metadata": {
    "id": "da25731b"
   },
   "source": [
    "<a name='section_20_7'></a>\n",
    "<hr style=\"height: 1px;\">\n",
    "\n",
    "## <h2 style=\"border:1px; border-style:solid; padding: 0.25em; color: #FFFFFF; background-color: #90409C\">L20.7 N-D Hydrodynamical Solutions</h2>  \n",
    "\n",
    "| [Top](#section_20_0) | [Previous Section](#section_20_6) | [Exercises](#exercises_20_7) |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c76c5dc",
   "metadata": {
    "id": "6c76c5dc"
   },
   "source": [
    "<h3>Overview</h3>\n",
    "\n",
    "A multi-dimensional version of the above equations starts from the Euler equation. We can write the Euler equation for conservation of mass\n",
    "\n",
    "$$\n",
    "\\frac{\\partial \\rho}{\\partial t} + \\nabla\\cdot (\\rho \\vec{u}) = 0\n",
    "$$\n",
    "\n",
    "Next, we can write the Euler equation for conservation of momentum as\n",
    "\n",
    "$$\n",
    "\\frac{\\partial \\rho \\vec{u} }{\\partial t} + \\nabla\\cdot (\\rho \\vec{u} \\otimes \\vec{u} + \\vec{P} ) = -\\rho\\nabla\\Phi\n",
    "$$\n",
    "\n",
    "where the term on the right is just the external force.\n",
    "\n",
    "Finally, we can write the Euler equation for conservation of Energy as\n",
    "\n",
    "$$\n",
    "\\frac{\\partial \\rho E }{\\partial t} + \\nabla\\cdot (\\rho E \\vec{u} + p\\vec{u} ) = 0\n",
    "$$\n",
    "\n",
    "Often they are written in vector form\n",
    "\n",
    "$$\n",
    "\\frac{\\partial q_{i}}{\\partial t} + \\frac{\\partial f}{\\partial q_{i}} = 0\n",
    "$$\n",
    "\n",
    "where we have\n",
    "\n",
    "$$\n",
    "f\n",
    "$$\n",
    "\n",
    "For $f$ one the of the functions above. The above set of equations, thus constitutes a set of coupled differential equations that we need to solve, and are in all practial purposes a generalization of the equations above. In light of this we are going to do something more complicated.\n",
    "\n",
    "Let's take our middle equation, and rewrite it slightly in a simpler form. We can write this as\n",
    "\n",
    "$$\n",
    "\\frac{d\\vec{v}}{dt} = -\\frac{1}{\\rho}\\nabla \\vec{P} - \\frac{1}{\\rho}\\vec{f}\n",
    "$$\n",
    "\n",
    "If we consider a spherically symetric setup, then we can write the pressure $P(r)=k\\rho^{1+1/n}$ essentially, we are just saying it scales with $\\rho$. Additionally, we can write the force $f(r)=-\\lambda r - \\nu v$ in terms of the gravitational pressurem $\\lambda$ and the viscosity $\\nu$\n",
    "\n",
    "Furthermore, if we treat each point a spherically symmetric Gaussian, we can write\n",
    "\n",
    "$$\n",
    "\\rho_{i}(r) = \\left(\\frac{1}{\\sigma\\sqrt{\\pi}}\\right)^{3} e^{-\\frac{r_{i}^2}{\\sigma^2}}\n",
    "$$\n",
    "\n",
    "The density at a specific point can then just given by the sum over all particles at that point\n",
    "\n",
    "$$\n",
    "\\rho(\\vec{r}) =  \\sum_{i} m_{i} \\rho_{i}\\left(\\vec{r}-\\vec{r_{i}}\\right)\n",
    "$$\n",
    "More over, with this discretiation, we can write\n",
    "$$\n",
    "\\nabla \\rho(\\vec{r}) =  \\sum_{i} m_{i} \\nabla \\rho_{i}\\left(\\vec{r}-\\vec{r_{i}}\\right)\n",
    "$$\n",
    "\n",
    "We can also write\n",
    "$$\n",
    "\\frac{1}{\\rho}\\nabla P = \\nabla\\left(\\frac{P}{\\rho}\\right)+\\frac{P}{\\rho^2}\\nabla\\rho\n",
    "$$\n",
    "\n",
    "Noting\n",
    "$$\n",
    "\\frac{P}{\\rho}(\\vec{r_{i}}) = \\sum_{j} \\frac{P_{j}}{\\rho^{2}_{j}} m_{j} \\rho_{j} \\left(\\vec{r_{i}}-\\vec{r_{j}}\\right)\\\\\n",
    "\\nabla\\left(\\frac{P_{i}}{\\rho}\\right) = \\sum_{j} \\frac{P_{j}}{\\rho^{2}_{j}} m_{j} \\nabla \\rho_{j} \\left(\\vec{r_{i}}-\\vec{r_{j}}\\right)\n",
    "$$\n",
    "\n",
    "Now combining this we have\n",
    "$$\n",
    "\\frac{1}{\\rho}\\nabla P = \\sum_{j\\neq i} \\left(\\frac{P_{i}}{\\rho^{2}_{i}} + \\frac{P_{j}}{\\rho^{2}_{j}}\\right)\\nabla \\rho_{j} \\left(\\vec{r_{i}}-\\vec{r_{j}}\\right)\n",
    "$$\n",
    "\n",
    "The resulting acceleration is thus\n",
    "\n",
    "$$\n",
    "\\frac{d\\vec{v}}{dt} = -\\sum_{j\\neq i} \\left(\\frac{P_{i}}{\\rho^{2}_{i}} + \\frac{P_{j}}{\\rho^{2}_{j}}\\right)\\nabla \\rho_{j} \\left(\\vec{r_{i}}-\\vec{r_{j}}\\right) + \\vec{f}\n",
    "$$\n",
    "\n",
    "\n",
    "More details here\n",
    "http://www.astro.yale.edu/vdbosch/Numerical_Hydrodynamics.pdf\n",
    "https://philip-mocz.medium.com/create-your-own-smoothed-particle-hydrodynamics-simulation-with-python-76e1cec505f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b54a9ed",
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "4b54a9ed",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from scipy.special import gamma\n",
    "\n",
    "def rhoP( x, y, z, h ):\n",
    "    r = np.sqrt(x**2 + y**2 + z**2)\n",
    "    w = (1.0 / (h*np.sqrt(np.pi)))**3 * np.exp( -r**2 / h**2)\n",
    "    return w\n",
    "\n",
    "def gradrhoP( x, y, z, h ):\n",
    "    r = np.sqrt(x**2 + y**2 + z**2)\n",
    "    n = -2 * np.exp( -r**2 / h**2) / h**5 / (np.pi)**(3/2)\n",
    "    wx = n * x\n",
    "    wy = n * y\n",
    "    wz = n * z\n",
    "    return wx, wy, wz\n",
    "\n",
    "def getPairwiseSeparations( ri, rj ):\n",
    "    M = ri.shape[0]\n",
    "    N = rj.shape[0]\n",
    "\n",
    "    # positions ri = (x,y,z)\n",
    "    rix = ri[:,0].reshape((M,1))\n",
    "    riy = ri[:,1].reshape((M,1))\n",
    "    riz = ri[:,2].reshape((M,1))\n",
    "\n",
    "    # other set of points positions rj = (x,y,z)\n",
    "    rjx = rj[:,0].reshape((N,1))\n",
    "    rjy = rj[:,1].reshape((N,1))\n",
    "    rjz = rj[:,2].reshape((N,1))\n",
    "\n",
    "    # matrices that store all pairwise particle separations: r_i - r_j\n",
    "    dx = rix - rjx.T\n",
    "    dy = riy - rjy.T\n",
    "    dz = riz - rjz.T\n",
    "\n",
    "    return dx, dy, dz\n",
    "\n",
    "def getDensity( r, pos, m, h ):\n",
    "    M = r.shape[0]\n",
    "    dx, dy, dz = getPairwiseSeparations( r, pos );\n",
    "    rho = np.sum( m * rhoP(dx, dy, dz, h), 1 ).reshape((M,1))\n",
    "    return rho\n",
    "\n",
    "def getPressure(rho, k, n):\n",
    "    P = k * rho**(1+1/n)\n",
    "    return P\n",
    "\n",
    "def getAcc( pos, vel, m, h, k, n, lmbda, nu ):\n",
    "    N = pos.shape[0]\n",
    "    rho = getDensity( pos, pos, m, h )\n",
    "\n",
    "    # Get the pressures\n",
    "    P = getPressure(rho, k, n)\n",
    "\n",
    "    # Get pairwise distances and gradients\n",
    "    dx, dy, dz = getPairwiseSeparations( pos, pos )\n",
    "    dWx, dWy, dWz = gradrhoP( dx, dy, dz, h )\n",
    "\n",
    "    # Add Pressure contribution to accelerations\n",
    "    tmp1 = P/rho**2\n",
    "    tmp2 =  P.T/rho.T**2\n",
    "    tmp  = ( P/rho**2 + P.T/rho.T**2  )\n",
    "    ax = - np.sum( m * ( P/rho**2 + P.T/rho.T**2  ) * dWx, 1).reshape((N,1))\n",
    "    ay = - np.sum( m * ( P/rho**2 + P.T/rho.T**2  ) * dWy, 1).reshape((N,1))\n",
    "    az = - np.sum( m * ( P/rho**2 + P.T/rho.T**2  ) * dWz, 1).reshape((N,1))\n",
    "\n",
    "    # pack together the acceleration components\n",
    "    a = np.hstack((ax,ay,az))\n",
    "\n",
    "    # Add external potential force and viscosity\n",
    "    a += -lmbda * pos - nu * vel\n",
    "\n",
    "    return a\n",
    "\n",
    "def makePlot(pos,ax1,ax2,fig,rho,images,rr,rlin,rho_analytic, m, h):\n",
    "    plt.sca(ax1)\n",
    "    plt.cla()\n",
    "    cval = np.minimum((rho-3)/3,1).flatten()\n",
    "    ax1.scatter(pos[:,0],pos[:,1], c=cval, cmap=plt.cm.autumn, s=10, alpha=0.5)\n",
    "    ax1.set(xlim=(-1.4, 1.4), ylim=(-1.2, 1.2))\n",
    "    ax1.set_aspect('equal', 'box')\n",
    "    ax1.set_xticks([-1,0,1])\n",
    "    ax1.set_yticks([-1,0,1])\n",
    "    ax1.set_facecolor('black')\n",
    "    ax1.set_facecolor((.1,.1,.1))\n",
    "\n",
    "    plt.sca(ax2)\n",
    "    plt.cla()\n",
    "    ax2.set(xlim=(0, 1), ylim=(0, 3))\n",
    "    ax2.set_aspect(0.1)\n",
    "    ax2.plot(rlin, rho_analytic, color='gray', linewidth=2)\n",
    "    rho_radial = getDensity( rr, pos, m, h )\n",
    "    ax2.plot(rlin, rho_radial, color='blue')\n",
    "\n",
    "    fig.canvas.draw()       # draw the canvas, cache the renderer\n",
    "    image = np.frombuffer(fig.canvas.tostring_rgb(), dtype='uint8')\n",
    "    image  = image.reshape(fig.canvas.get_width_height()[::-1] + (3,))\n",
    "    images.append(image)\n",
    "\n",
    "def main(plotRealTime = True ):\n",
    "    # Simulation parameters\n",
    "    N         = 400    # Number of particles\n",
    "    t         = 0      # current time of the simulation\n",
    "    tEnd      = 12     # time at which simulation ends\n",
    "    dt        = 0.04   # timestep\n",
    "    M         = 2      # star mass\n",
    "    R         = 0.75   # star radius\n",
    "    h         = 0.1    # smoothing length\n",
    "    k         = 0.1    # equation of state constant\n",
    "    n         = 1      # polytropic index\n",
    "    nu        = 1      # damping\n",
    "\n",
    "    # Generate Initial Conditions\n",
    "    np.random.seed(42)            # set the random number generator seed\n",
    "\n",
    "    lmbda = 2*k*(1+n)*np.pi**(-3/(2*n)) * (M*gamma(5/2+n)/R**3/gamma(1+n))**(1/n) / R**2  # ~ 2.01\n",
    "    m     = M/N                    # single particle mass\n",
    "    pos   = np.random.randn(N,3)   # randomly selected positions and velocities\n",
    "    vel   = np.zeros(pos.shape)\n",
    "\n",
    "    # calculate initial gravitational accelerations\n",
    "    acc = getAcc( pos, vel, m, h, k, n, lmbda, nu )\n",
    "\n",
    "    # number of timesteps\n",
    "    Nt = int(np.ceil(tEnd/dt))\n",
    "\n",
    "    # prep figure\n",
    "    fig, ax1 = plt.subplots(figsize=(12,7))\n",
    "    grid = plt.GridSpec(3, 1, wspace=0.0, hspace=0.3)\n",
    "    ax1 = plt.subplot(grid[0:2,0])\n",
    "    ax2 = plt.subplot(grid[2,0])\n",
    "    rr = np.zeros((100,3))\n",
    "    rlin = np.linspace(0,1,100)\n",
    "    rr[:,0] =rlin\n",
    "    rho_analytic = lmbda/(4*k) * (R**2 - rlin**2)\n",
    "    images=[]\n",
    "\n",
    "    # Simulation Main Loop\n",
    "    for i in range(Nt):\n",
    "        vel += acc * dt/2\n",
    "        pos += vel * dt\n",
    "        # update accelerations\n",
    "        acc = getAcc( pos, vel, m, h, k, n, lmbda, nu )\n",
    "        vel += acc * dt/2\n",
    "        # update timef\n",
    "        t += dt\n",
    "        # get density for plottiny\n",
    "        rho = getDensity( pos, pos, m, h )\n",
    "\n",
    "        # plot in real time\n",
    "        if plotRealTime or (i == Nt-1):\n",
    "            makePlot(pos,ax1,ax2,fig, rho, images,rr,rlin,rho_analytic,m,h)\n",
    "\n",
    "    # add labels/legend\n",
    "    plt.sca(ax2)\n",
    "    plt.xlabel('radius')\n",
    "    plt.ylabel('density')\n",
    "\n",
    "    # Save figure\n",
    "    plt.savefig('sph.png',dpi=240)\n",
    "    plt.show()\n",
    "    return images\n",
    "\n",
    "images=main()\n",
    "imageio.mimsave('data/L15/xstar.gif', images, fps=10)\n",
    "Image(open('data/L15/xstar.gif','rb').read())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "451c9aa8",
   "metadata": {
    "id": "451c9aa8"
   },
   "outputs": [],
   "source": [
    "Image(open('data/L15/star.gif','rb').read())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52f3102f",
   "metadata": {
    "id": "52f3102f"
   },
   "source": [
    "<a name='exercises_20_7'></a>     \n",
    "\n",
    "| [Top](#section_20_0) | [Restart Section](#section_20_7) |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "047513be",
   "metadata": {
    "id": "047513be"
   },
   "source": [
    "### <span style=\"border:3px; border-style:solid; padding: 0.15em; border-color: #90409C; color: #90409C;\">Ex-20.7.1 </span>\n",
    "\n",
    "<br>"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Tags",
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
